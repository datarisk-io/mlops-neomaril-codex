{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neomaril Models\n",
    "\n",
    "This notebook give a exemple on how to use Neomaril to deploy a ML model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NeomarilModelClient\n",
    "\n",
    "It's where you can manage your models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the client\n",
    "from neomaril_codex.model import NeomarilModelClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-17 16:05:30.542 | INFO     | neomaril_codex._base:__init__:77 - Loading .env\n",
      "2023-02-17 16:05:30.980 | INFO     | neomaril_codex._base:__init__:89 - Successfully connected to Neomaril\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "NeomarilModelClient(url=\"http://localhost:7070/api\", version=\"1.0\")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Start the client. We are reading the credentials in the NEOMARIL_TOKEN env variable\n",
    "client = NeomarilModelClient()\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NeomarilModel\n",
    "\n",
    "It's where you can use your model after you fetch it with the client (or created a new one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-17 16:05:31.010 | INFO     | neomaril_codex.model:create_model:562 - Group not informed, using default 'datarisk' group\n",
      "2023-02-17 16:05:33.618 | INFO     | neomaril_codex.model:__upload_model:492 - Model 'Teste notebook Sync' inserted - Hash: \"M712840628b34dbcbdcf0a12920f2f8886e9b382b2844cb3b2fd0fd9d1c49326\"\n",
      "2023-02-17 16:05:35.300 | INFO     | neomaril_codex.model:__host_model:516 - Model host in process - Hash: M712840628b34dbcbdcf0a12920f2f8886e9b382b2844cb3b2fd0fd9d1c49326\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wating for deploy to be ready..............."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-17 16:08:01.962 | INFO     | neomaril_codex.model:get_model:369 - Model M712840628b34dbcbdcf0a12920f2f8886e9b382b2844cb3b2fd0fd9d1c49326 its deployed. Fetching model.\n",
      "2023-02-17 16:08:01.964 | INFO     | neomaril_codex.model:__init__:31 - Loading .env\n"
     ]
    }
   ],
   "source": [
    "# Or create a new one\n",
    "\n",
    "PATH = './samples/syncModel/'\n",
    "\n",
    "# Deploying a new model\n",
    "model = client.create_model('Teste notebook Sync', # model_name\n",
    "                            'score', # name of the scoring function\n",
    "                            PATH+'app.py', # Path of the source file\n",
    "                            PATH+'model.pkl', # Path of the model pkl file, \n",
    "                            PATH+'requirements.txt', # Path of the requirements file, \n",
    "                            PATH+'schema.json', # Path of the schema file, but it could be a dict\n",
    "#                           env=PATH+'.env'  #  File for env variables (this will be encrypted in the server)\n",
    "#                           extra_files=[PATH+'utils.py'], # List with extra files paths that should be uploaded along (they will be all in the same folder)\n",
    "                            python_version='3.9', # Can be 3.7 to 3.10\n",
    "                            operation=\"Sync\" # Can be Sync or Async\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeomarilModel(name=\"Teste notebook Sync\", group=\"datarisk\", \n",
       "                                status=\"Deployed\",\n",
       "                                model_id=\"M712840628b34dbcbdcf0a12920f2f8886e9b382b2844cb3b2fd0fd9d1c49326\",\n",
       "                                operation=\"Sync\",\n",
       "                                schema={\n",
       "  \"mean_radius\": 17.99,\n",
       "  \"mean_texture\": 10.38,\n",
       "  \"mean_perimeter\": 122.8,\n",
       "  \"mean_area\": 1001.0,\n",
       "  \"mean_smoothness\": 0.1184,\n",
       "  \"mean_compactness\": 0.2776,\n",
       "  \"mean_concavity\": 0.3001,\n",
       "  \"mean_concave_points\": 0.1471,\n",
       "  \"mean_symmetry\": 0.2419,\n",
       "  \"mean_fractal_dimension\": 0.07871,\n",
       "  \"radius_error\": 1.095,\n",
       "  \"texture_error\": 0.9053,\n",
       "  \"perimeter_error\": 8.589,\n",
       "  \"area_error\": 153.4,\n",
       "  \"smoothness_error\": 0.006399,\n",
       "  \"compactness_error\": 0.04904,\n",
       "  \"concavity_error\": 0.05373,\n",
       "  \"concave_points_error\": 0.01587,\n",
       "  \"symmetry_error\": 0.03003,\n",
       "  \"fractal_dimension_error\": 0.006193,\n",
       "  \"worst_radius\": 25.38,\n",
       "  \"worst_texture\": 17.33,\n",
       "  \"worst_perimeter\": 184.6,\n",
       "  \"worst_area\": 2019.0,\n",
       "  \"worst_smoothness\": 0.1622,\n",
       "  \"worst_compactness\": 0.6656,\n",
       "  \"worst_concavity\": 0.7119,\n",
       "  \"worst_concave_points\": 0.2654,\n",
       "  \"worst_symmetry\": 0.4601,\n",
       "  \"worst_fractal_dimension\": 0.1189\n",
       "}\n",
       "                                )"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-17 16:08:02.933 | INFO     | neomaril_codex.model:set_token:161 - Token for group datarisk added.\n"
     ]
    }
   ],
   "source": [
    "# set group token for this model (you can also add this token in each .predict call or as a env variable NEOMARIL_GROUP_TOKEN)\n",
    "model.set_token('TODO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ModelHash': 'M712840628b34dbcbdcf0a12920f2f8886e9b382b2844cb3b2fd0fd9d1c49326', 'Operation': 'Sync', 'PythonVersion': 'Python39', 'Status': 'Deployed', 'Name': 'Teste notebook Sync', 'Group': 'datarisk', 'UploadedAt': '2023-02-17T19:05:33.3637640Z', 'Schema': '{\\n  \"mean_radius\": 17.99,\\n  \"mean_texture\": 10.38,\\n  \"mean_perimeter\": 122.8,\\n  \"mean_area\": 1001.0,\\n  \"mean_smoothness\": 0.1184,\\n  \"mean_compactness\": 0.2776,\\n  \"mean_concavity\": 0.3001,\\n  \"mean_concave_points\": 0.1471,\\n  \"mean_symmetry\": 0.2419,\\n  \"mean_fractal_dimension\": 0.07871,\\n  \"radius_error\": 1.095,\\n  \"texture_error\": 0.9053,\\n  \"perimeter_error\": 8.589,\\n  \"area_error\": 153.4,\\n  \"smoothness_error\": 0.006399,\\n  \"compactness_error\": 0.04904,\\n  \"concavity_error\": 0.05373,\\n  \"concave_points_error\": 0.01587,\\n  \"symmetry_error\": 0.03003,\\n  \"fractal_dimension_error\": 0.006193,\\n  \"worst_radius\": 25.38,\\n  \"worst_texture\": 17.33,\\n  \"worst_perimeter\": 184.6,\\n  \"worst_area\": 2019.0,\\n  \"worst_smoothness\": 0.1622,\\n  \"worst_compactness\": 0.6656,\\n  \"worst_concavity\": 0.7119,\\n  \"worst_concave_points\": 0.2654,\\n  \"worst_symmetry\": 0.4601,\\n  \"worst_fractal_dimension\": 0.1189\\n}'}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Teste notebook Sync\n",
      "----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "  \"mean_radius\": 17.99,\n",
      "  \"mean_texture\": 10.38,\n",
      "  \"mean_perimeter\": 122.8,\n",
      "  \"mean_area\": 1001.0,\n",
      "  \"mean_smoothness\": 0.1184,\n",
      "  \"mean_compactness\": 0.2776,\n",
      "  \"mean_concavity\": 0.3001,\n",
      "  \"mean_concave_points\": 0.1471,\n",
      "  \"mean_symmetry\": 0.2419,\n",
      "  \"mean_fractal_dimension\": 0.07871,\n",
      "  \"radius_error\": 1.095,\n",
      "  \"texture_error\": 0.9053,\n",
      "  \"perimeter_error\": 8.589,\n",
      "  \"area_error\": 153.4,\n",
      "  \"smoothness_error\": 0.006399,\n",
      "  \"compactness_error\": 0.04904,\n",
      "  \"concavity_error\": 0.05373,\n",
      "  \"concave_points_error\": 0.01587,\n",
      "  \"symmetry_error\": 0.03003,\n",
      "  \"fractal_dimension_error\": 0.006193,\n",
      "  \"worst_radius\": 25.38,\n",
      "  \"worst_texture\": 17.33,\n",
      "  \"worst_perimeter\": 184.6,\n",
      "  \"worst_area\": 2019.0,\n",
      "  \"worst_smoothness\": 0.1622,\n",
      "  \"worst_compactness\": 0.6656,\n",
      "  \"worst_concavity\": 0.7119,\n",
      "  \"worst_concave_points\": 0.2654,\n",
      "  \"worst_symmetry\": 0.4601,\n",
      "  \"worst_fractal_dimension\": 0.1189\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# All the information about the model can be acessed\n",
    "print(model.model_data)\n",
    "print('-'*100)\n",
    "print(model.name)\n",
    "print('-'*100)\n",
    "print(model.schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'error': {'message': 'InvalidBearerToken: The token provided is not seen as valid.'}}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "{'error': {'message': 'InvalidBearerToken: The token provided is not seen as valid.'}}\n"
     ]
    }
   ],
   "source": [
    "# Run predictions with the predict method, or just call it with the model object\n",
    "print(model.predict(model.schema))\n",
    "print('-'*100)\n",
    "print(model(model.schema))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-17 16:08:04.907 | ERROR    | neomaril_codex.model:register_monitoring:281 - Upload error: \"Query\\n  System.InvalidOperationException: Encountered zero elements in the input sequence\\n   at Microsoft.FSharp.Linq.QueryModule.CallGenericStaticMethod@374.Invoke(Tuple`2 tupledArg) in D:\\\\a\\\\_work\\\\1\\\\s\\\\src\\\\fsharp\\\\FSharp.Core\\\\Query.fs:line 379\\n   at Microsoft.FSharp.Linq.QueryModule.clo@1926-18.Microsoft.FSharp.Linq.ForwardDeclarations.IQueryMethods.Execute[a,b](FSharpExpr`1 q) in D:\\\\a\\\\_work\\\\1\\\\s\\\\src\\\\fsharp\\\\FSharp.Core\\\\Query.fs:line 1928\\n   at Services.Controller.TrainingExecution.getById(Int32 id) in /app/source/Services/Controllers/TrainingExecution.fs:line 24\"\n"
     ]
    },
    {
     "ename": "InputError",
     "evalue": "Invalid parameters for model creation",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInputError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# We can also add a monitoring configuration for the model\u001b[39;00m\n\u001b[1;32m      3\u001b[0m PATH \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m./samples/monitoring/\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m----> 5\u001b[0m model\u001b[39m.\u001b[39;49mregister_monitoring(\u001b[39m'\u001b[39;49m\u001b[39mparse\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m# name of the preprocess function\u001b[39;49;00m\n\u001b[1;32m      6\u001b[0m                           \u001b[39m'\u001b[39;49m\u001b[39mget_shap\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m# name of the preprocess function\u001b[39;49;00m\n\u001b[1;32m      7\u001b[0m                           configuration_file\u001b[39m=\u001b[39;49mPATH\u001b[39m+\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mconfiguration.json\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m# Path of the configuration file, but it could be a dict\u001b[39;49;00m\n\u001b[1;32m      8\u001b[0m                           preprocess_file\u001b[39m=\u001b[39;49mPATH\u001b[39m+\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mpreprocess_sync.py\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m# Path of the preprocess script\u001b[39;49;00m\n\u001b[1;32m      9\u001b[0m                           requirements_file\u001b[39m=\u001b[39;49mPATH\u001b[39m+\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mrequirements.txt\u001b[39;49m\u001b[39m'\u001b[39;49m \u001b[39m# Path of the requirements file                        \u001b[39;49;00m\n\u001b[1;32m     10\u001b[0m )\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/neomaril-codex-WNTK3WJm/lib/python3.10/site-packages/neomaril_codex/model.py:282\u001b[0m, in \u001b[0;36mNeomarilModel.register_monitoring\u001b[0;34m(self, preprocess_reference, shap_reference, configuration_file, preprocess_file, requirements_file)\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    281\u001b[0m     logger\u001b[39m.\u001b[39merror(\u001b[39m'\u001b[39m\u001b[39mUpload error: \u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m response\u001b[39m.\u001b[39mtext)\n\u001b[0;32m--> 282\u001b[0m     \u001b[39mraise\u001b[39;00m InputError(\u001b[39m'\u001b[39m\u001b[39mInvalid parameters for model creation\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mInputError\u001b[0m: Invalid parameters for model creation"
     ]
    }
   ],
   "source": [
    "# We can also add a monitoring configuration for the model\n",
    "\n",
    "PATH = './samples/monitoring/'\n",
    "\n",
    "model.register_monitoring('parse', # name of the preprocess function\n",
    "                          'get_shap', # name of the preprocess function\n",
    "                          configuration_file=PATH+'configuration.json', # Path of the configuration file, but it could be a dict\n",
    "                          preprocess_file=PATH+'preprocess_sync.py', # Path of the preprocess script\n",
    "                          requirements_file=PATH+'requirements.txt' # Path of the requirements file                        \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NeomarilAsyncModelExecution\n",
    "We can create async models as well to send bigger data to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-31 15:47:04.124 | INFO     | neomaril_codex.model:create_model:514 - Group not informed, using default 'datarisk' group\n",
      "2023-01-31 15:47:04.144 | INFO     | neomaril_codex.model:__upload_model:444 - Model 'Teste notebook Async' inserted - Hash: \"M9c3af308c754ee7b96b2f4a273984414d40a33be90242908f9fc4aa28ba8ec4\"\n",
      "2023-01-31 15:47:04.159 | INFO     | neomaril_codex.model:__host_model:468 - Model host in process - Hash: M9c3af308c754ee7b96b2f4a273984414d40a33be90242908f9fc4aa28ba8ec4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wating for deploy to be ready..............."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-31 15:49:24.452 | INFO     | neomaril_codex.model:get_model:321 - Model M9c3af308c754ee7b96b2f4a273984414d40a33be90242908f9fc4aa28ba8ec4 its deployed. Fetching model.\n"
     ]
    }
   ],
   "source": [
    "PATH = './samples/asyncModel/'\n",
    "\n",
    "# Deploying a new model\n",
    "model = client.create_model('Teste notebook Async', # model_name\n",
    "                            'score', # name of the scoring function\n",
    "                            PATH+'app.py', # Path of the source file\n",
    "                            PATH+'model.pkl', # Path of the model pkl file, \n",
    "                            PATH+'requirements.txt', # Path of the requirements file, \n",
    "#                           env=PATH+'.env'  #  File for env variables (this will be encrypted in the server)\n",
    "#                           extra_files=[PATH+'utils.py'], # List with extra files paths that should be uploaded along (they will be all in the same folder)\n",
    "                            python_version='3.9', # Can be 3.7 to 3.10\n",
    "                            operation=\"Async\", # Can be Sync or Async\n",
    "                            input_type='csv'# Can be json or csv or parquet\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-31 15:49:25.070 | INFO     | neomaril_codex.model:predict:154 - Execution 3 started. Use the id to check its status.\n"
     ]
    }
   ],
   "source": [
    "execution = model.predict(PATH+'input.csv', group_token='TODO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ModelHash': 'M9c3af308c754ee7b96b2f4a273984414d40a33be90242908f9fc4aa28ba8ec4',\n",
       " 'Operation': 'Async',\n",
       " 'PythonVersion': 'Python39',\n",
       " 'Status': 'Requested',\n",
       " 'Name': 'Teste notebook Async',\n",
       " 'Group': 'datarisk',\n",
       " 'UploadedAt': '2023-01-31T18:47:04.1406680Z',\n",
       " 'Schema': '{}',\n",
       " 'ExecutionId': 3,\n",
       " 'RunAt': '2023-01-31T18:49:24.5569460Z',\n",
       " 'ExecutionState': 'Running',\n",
       " 'InputPayload': '{\\n    \"executionType\": \"neomaril-runAsync\",\\n    \"basePath\": \"/app/store/datarisk/M9c3af308c754ee7b96b2f4a273984414d40a33be90242908f9fc4aa28ba8ec4\",\\n    \"neomarilExecutionId\": \"3\"\\n}',\n",
       " 'OutputPayload': '{\\n    \"outputMessage\": [],\\n    \"outputPath\": \"/app/store/datarisk/M9c3af308c754ee7b96b2f4a273984414d40a33be90242908f9fc4aa28ba8ec4/3/output/3.zip\"\\n}'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "execution.execution_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'modelExecutionId': '3', 'Status': 'Running', 'Message': None}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "execution.get_status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-31 15:52:20.426 | INFO     | neomaril_codex._base:download_result:261 - Output saved in ./output_3.zip\n"
     ]
    }
   ],
   "source": [
    "execution.download_result()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neomaril-codex-WNTK3WJm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "d7308033b61508a213f02f142180c32f76fea0bd8e107ff2b0f7849d3585655c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
