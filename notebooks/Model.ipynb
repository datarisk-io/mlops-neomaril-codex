{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neomaril Models\n",
    "\n",
    "This notebook give a exemple on how to use Neomaril to deploy a ML model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NeomarilModelClient\n",
    "\n",
    "It's where you can manage your models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the client\n",
    "from neomaril_codex.model import NeomarilModelClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-16 15:19:09.008 | INFO     | neomaril_codex.model:__init__:722 - Loading .env\n",
      "2023-10-16 15:19:09.009 | INFO     | neomaril_codex.base:__init__:90 - Loading .env\n",
      "2023-10-16 15:19:10.444 | INFO     | neomaril_codex.base:__init__:102 - Successfully connected to Neomaril\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "NeomarilModelClient(url=\"http://localhost:7070/api\", version=\"1.0\")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Start the client. We are reading the credentials in the NEOMARIL_TOKEN env variable\n",
    "client = NeomarilModelClient()\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NeomarilModel\n",
    "\n",
    "It's where you can use your model after you fetch it with the client (or created a new one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-16 15:19:14.132 | INFO     | neomaril_codex.model:__upload_model:1015 - Model 'Teste notebook Sync' inserted - Hash: \"Mef9470be2f148b6bfb5220ae49ad1eb211c4c7287b94ddca88fc3627b1c23ee\"\n",
      "2023-10-16 15:19:16.207 | INFO     | neomaril_codex.model:__host_model:1046 - Model host in process - Hash: Mef9470be2f148b6bfb5220ae49ad1eb211c4c7287b94ddca88fc3627b1c23ee\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wating for deploy to be ready........"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-16 15:20:37.819 | INFO     | neomaril_codex.model:get_model:820 - Model Mef9470be2f148b6bfb5220ae49ad1eb211c4c7287b94ddca88fc3627b1c23ee its deployed. Fetching model.\n",
      "2023-10-16 15:20:37.821 | INFO     | neomaril_codex.model:__init__:69 - Loading .env\n"
     ]
    }
   ],
   "source": [
    "# Or create a new one\n",
    "\n",
    "PATH = './samples/syncModel/'\n",
    "\n",
    "# Deploying a new model\n",
    "model = client.create_model('Teste notebook Sync', # model_name\n",
    "                            'score', # name of the scoring function\n",
    "                            PATH+'app.py', # Path of the source file\n",
    "                            PATH+'model.pkl', # Path of the model pkl file, \n",
    "                            PATH+'requirements.txt', # Path of the requirements file, \n",
    "                            schema=PATH+'schema.json', # Path of the schema file, but it could be a dict (only required for Sync models)\n",
    "#                           env=PATH+'.env'  #  File for env variables (this will be encrypted in the server)\n",
    "#                           extra_files=[PATH+'utils.py'], # List with extra files paths that should be uploaded along (they will be all in the same folder)\n",
    "                            python_version='3.9', # Can be 3.7 to 3.10\n",
    "                            operation=\"Sync\", # Can be Sync or Async\n",
    "                            group='datarisk' # Model group (create one using the client)\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeomarilModel(name=\"Teste notebook Sync\", group=\"datarisk\", \n",
       "                                status=\"Deployed\",\n",
       "                                model_id=\"Mef9470be2f148b6bfb5220ae49ad1eb211c4c7287b94ddca88fc3627b1c23ee\",\n",
       "                                operation=\"Sync\",\n",
       "                                schema={'mean_radius': 17.99, 'mean_texture': 10.38, 'mean_perimeter': 122.8, 'mean_area': 1001.0, 'mean_smoothness': 0.1184, 'mean_compactness': 0.2776, 'mean_concavity': 0.3001, 'mean_concave_points': 0.1471, 'mean_symmetry': 0.2419, 'mean_fractal_dimension': 0.07871, 'radius_error': 1.095, 'texture_error': 0.9053, 'perimeter_error': 8.589, 'area_error': 153.4, 'smoothness_error': 0.006399, 'compactness_error': 0.04904, 'concavity_error': 0.05373, 'concave_points_error': 0.01587, 'symmetry_error': 0.03003, 'fractal_dimension_error': 0.006193, 'worst_radius': 25.38, 'worst_texture': 17.33, 'worst_perimeter': 184.6, 'worst_area': 2019.0, 'worst_smoothness': 0.1622, 'worst_compactness': 0.6656, 'worst_concavity': 0.7119, 'worst_concave_points': 0.2654, 'worst_symmetry': 0.4601, 'worst_fractal_dimension': 0.1189}\n",
       "                                )"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-16 15:20:40.923 | INFO     | neomaril_codex.model:set_token:297 - Token for group datarisk added.\n"
     ]
    }
   ],
   "source": [
    "# set group token for this model (you can also add this token in each .predict call or as a env variable NEOMARIL_GROUP_TOKEN)\n",
    "model.set_token('TODO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ModelHash': 'Mef9470be2f148b6bfb5220ae49ad1eb211c4c7287b94ddca88fc3627b1c23ee', 'TrainingHash': None, 'TrainingExecution': None, 'RunName': '', 'Operation': 'Sync', 'PythonVersion': 'Python39', 'Status': 'Deployed', 'Name': 'Teste notebook Sync', 'Group': 'datarisk', 'UploadedAt': '2023-10-16T18:19:14.129188Z', 'Schema': {'mean_radius': 17.99, 'mean_texture': 10.38, 'mean_perimeter': 122.8, 'mean_area': 1001.0, 'mean_smoothness': 0.1184, 'mean_compactness': 0.2776, 'mean_concavity': 0.3001, 'mean_concave_points': 0.1471, 'mean_symmetry': 0.2419, 'mean_fractal_dimension': 0.07871, 'radius_error': 1.095, 'texture_error': 0.9053, 'perimeter_error': 8.589, 'area_error': 153.4, 'smoothness_error': 0.006399, 'compactness_error': 0.04904, 'concavity_error': 0.05373, 'concave_points_error': 0.01587, 'symmetry_error': 0.03003, 'fractal_dimension_error': 0.006193, 'worst_radius': 25.38, 'worst_texture': 17.33, 'worst_perimeter': 184.6, 'worst_area': 2019.0, 'worst_smoothness': 0.1622, 'worst_compactness': 0.6656, 'worst_concavity': 0.7119, 'worst_concave_points': 0.2654, 'worst_symmetry': 0.4601, 'worst_fractal_dimension': 0.1189}, 'ExecutionType': 'PythonScript', 'ModelReference': 'score', 'Input': 'json'}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Teste notebook Sync\n",
      "----------------------------------------------------------------------------------------------------\n",
      "{'mean_radius': 17.99, 'mean_texture': 10.38, 'mean_perimeter': 122.8, 'mean_area': 1001.0, 'mean_smoothness': 0.1184, 'mean_compactness': 0.2776, 'mean_concavity': 0.3001, 'mean_concave_points': 0.1471, 'mean_symmetry': 0.2419, 'mean_fractal_dimension': 0.07871, 'radius_error': 1.095, 'texture_error': 0.9053, 'perimeter_error': 8.589, 'area_error': 153.4, 'smoothness_error': 0.006399, 'compactness_error': 0.04904, 'concavity_error': 0.05373, 'concave_points_error': 0.01587, 'symmetry_error': 0.03003, 'fractal_dimension_error': 0.006193, 'worst_radius': 25.38, 'worst_texture': 17.33, 'worst_perimeter': 184.6, 'worst_area': 2019.0, 'worst_smoothness': 0.1622, 'worst_compactness': 0.6656, 'worst_concavity': 0.7119, 'worst_concave_points': 0.2654, 'worst_symmetry': 0.4601, 'worst_fractal_dimension': 0.1189}\n"
     ]
    }
   ],
   "source": [
    "# All the information about the model can be acessed\n",
    "print(model.model_data)\n",
    "print('-'*100)\n",
    "print(model.name)\n",
    "print('-'*100)\n",
    "print(model.schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pred': 0, 'proba': 0.005841062869876623}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "{'pred': 0, 'proba': 0.005841062869876623}\n"
     ]
    }
   ],
   "source": [
    "# Run predictions with the predict method, or just call it with the model object\n",
    "print(model.predict(model.schema))\n",
    "print('-'*100)\n",
    "print(model(model.schema))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:7071/api/model/sync/docs/datarisk/Mef9470be2f148b6bfb5220ae49ad1eb211c4c7287b94ddca88fc3627b1c23ee\n",
      "----------------------------------------------------------------------------------------------------\n",
      "curl --request POST \\\n",
      "                    --url http://localhost:7071/api/model/sync/run/datarisk/Mef9470be2f148b6bfb5220ae49ad1eb211c4c7287b94ddca88fc3627b1c23ee \\\n",
      "                    --header 'Authorization: Bearer TOKEN' \\\n",
      "                    --header 'Content-Type: application/json' \\\n",
      "                    --data '{\"Input\": {\"mean_radius\": 17.99, \"mean_texture\": 10.38, \"mean_perimeter\": 122.8, \"mean_area\": 1001.0, \"mean_smoothness\": 0.1184, \"mean_compactness\": 0.2776, \"mean_concavity\": 0.3001, \"mean_concave_points\": 0.1471, \"mean_symmetry\": 0.2419, \"mean_fractal_dimension\": 0.07871, \"radius_error\": 1.095, \"texture_error\": 0.9053, \"perimeter_error\": 8.589, \"area_error\": 153.4, \"smoothness_error\": 0.006399, \"compactness_error\": 0.04904, \"concavity_error\": 0.05373, \"concave_points_error\": 0.01587, \"symmetry_error\": 0.03003, \"fractal_dimension_error\": 0.006193, \"worst_radius\": 25.38, \"worst_texture\": 17.33, \"worst_perimeter\": 184.6, \"worst_area\": 2019.0, \"worst_smoothness\": 0.1622, \"worst_compactness\": 0.6656, \"worst_concavity\": 0.7119, \"worst_concave_points\": 0.2654, \"worst_symmetry\": 0.4601, \"worst_fractal_dimension\": 0.1189}}'\n",
      "                \n"
     ]
    }
   ],
   "source": [
    "# Serve your model for external clients\n",
    "print(model.docs)\n",
    "print('-'*100)\n",
    "print(model.generate_predict_code(language='curl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # We can also add a monitoring configuration for the model\n",
    "\n",
    "# PATH = './samples/monitoring/'\n",
    "\n",
    "# model.register_monitoring('parse', # name of the preprocess function\n",
    "#                           'get_shap', # name of the preprocess function\n",
    "#                           configuration_file=PATH+'configuration.json', # Path of the configuration file, but it could be a dict\n",
    "#                           preprocess_file=PATH+'preprocess_sync.py', # Path of the preprocess script\n",
    "#                           requirements_file=PATH+'requirements.txt' # Path of the requirements file                        \n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NeomarilAsyncModelExecution\n",
    "We can create async models as well to send bigger data to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-16 15:20:44.312 | INFO     | neomaril_codex.model:__upload_model:1015 - Model 'Teste notebook Async' inserted - Hash: \"Md704155dfad4fed8c41fc75af10ed2fb6a80f4239ca4d258e6dc2c8957cffcf\"\n",
      "2023-10-16 15:20:46.056 | INFO     | neomaril_codex.model:__host_model:1046 - Model host in process - Hash: Md704155dfad4fed8c41fc75af10ed2fb6a80f4239ca4d258e6dc2c8957cffcf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wating for deploy to be ready......................."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-16 15:24:59.492 | INFO     | neomaril_codex.model:get_model:820 - Model Md704155dfad4fed8c41fc75af10ed2fb6a80f4239ca4d258e6dc2c8957cffcf its deployed. Fetching model.\n",
      "2023-10-16 15:24:59.493 | INFO     | neomaril_codex.model:__init__:69 - Loading .env\n"
     ]
    }
   ],
   "source": [
    "PATH = './samples/asyncModel/'\n",
    "\n",
    "# Deploying a new model\n",
    "model = client.create_model('Teste notebook Async', # model_name\n",
    "                            'score', # name of the scoring function\n",
    "                            PATH+'app.py', # Path of the source file\n",
    "                            PATH+'model.pkl', # Path of the model pkl file, \n",
    "                            PATH+'requirements.txt', # Path of the requirements file, \n",
    "#                           env=PATH+'.env'  #  File for env variables (this will be encrypted in the server)\n",
    "#                           extra_files=[PATH+'utils.py'], # List with extra files paths that should be uploaded along (they will be all in the same folder)\n",
    "                            python_version='3.9', # Can be 3.7 to 3.10\n",
    "                            operation=\"Async\", # Can be Sync or Async\n",
    "                            input_type='csv',# Can be json or csv or parquet\n",
    "                            group='datarisk' # Model group (create one using the client)\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-16 15:25:03.878 | INFO     | neomaril_codex.model:predict:365 - Execution '10' started. Use the id to check its status.\n",
      "2023-10-16 15:25:03.879 | INFO     | neomaril_codex.base:__init__:279 - Loading .env\n"
     ]
    }
   ],
   "source": [
    "PATH = './samples/asyncModel/'\n",
    "execution = model.predict(PATH+'input.csv', group_token='TODO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ModelHash': 'Md704155dfad4fed8c41fc75af10ed2fb6a80f4239ca4d258e6dc2c8957cffcf',\n",
       " 'Operation': 'Async',\n",
       " 'PythonVersion': 'Python39',\n",
       " 'Status': 'Deployed',\n",
       " 'Name': 'Teste notebook Async',\n",
       " 'Group': 'datarisk',\n",
       " 'UploadedAt': '2023-10-16T18:20:44.308892Z',\n",
       " 'Schema': {},\n",
       " 'ExecutionId': 10,\n",
       " 'RunAt': '2023-10-16T18:25:03.578356Z',\n",
       " 'ExecutionState': 'Running',\n",
       " 'InputPayload': {'executionType': 'neomaril-runAsync',\n",
       "  'basePath': '/app/store/datarisk/Md704155dfad4fed8c41fc75af10ed2fb6a80f4239ca4d258e6dc2c8957cffcf',\n",
       "  'neomarilExecutionId': '10',\n",
       "  'defaultEnvVars': {'inputFileName': 'input.csv'}},\n",
       " 'OutputPayload': {'outputMessage': [],\n",
       "  'outputPath': '/app/store/datarisk/Md704155dfad4fed8c41fc75af10ed2fb6a80f4239ca4d258e6dc2c8957cffcf/10/output/10.zip'}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "execution.execution_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ExecutionId': '10', 'Status': 'Running', 'Message': None}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "execution.get_status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-16 15:28:39.129 | INFO     | neomaril_codex.base:download_result:413 - Output saved in ./output.zip\n"
     ]
    }
   ],
   "source": [
    "execution.wait_ready()\n",
    "execution.download_result()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neomaril-codex-WNTK3WJm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "d7308033b61508a213f02f142180c32f76fea0bd8e107ff2b0f7849d3585655c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
