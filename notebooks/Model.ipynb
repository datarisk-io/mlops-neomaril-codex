{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neomaril Models\n",
    "\n",
    "This notebook give a exemple on how to use Neomaril to deploy a ML model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NeomarilModelClient\n",
    "\n",
    "It's where you can manage your models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-06T12:14:05.345114Z",
     "start_time": "2024-08-06T12:14:05.269438Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import the client\n",
    "from neomaril_codex.model import NeomarilModelClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-06T12:19:12.036936Z",
     "start_time": "2024-08-06T12:19:10.702174Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "October 17, 2024 | INFO: __init__ Loading .env\n",
      "October 17, 2024 | INFO: __init__ Successfully connected to Neomaril\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "API version 1.0 - NeomarilModelClient(url=\"http://localhost:7070/api\", Token=\"eyJhbGciOiJSUzI1NiIsInR5cCI6IkpXVCIsImtpZCI6IlFnc0JWQ0I5WFc0V1YtSkVCVkJiZyJ9.eyJodHRwczovL25lb21hcmlsLmRhdGFyaXNrLm5ldC9uZW9tYXJpbC1ncm91cCI6ImRhdGFyaXNrIiwiaHR0cHM6Ly9uZW9tYXJpbC5kYXRhcmlzay5uZXQvZW1haWwiOiJuZW9tYXJpbC1jaUBkYXRhcmlzay5pbyIsImh0dHBzOi8vbmVvbWFyaWwuZGF0YXJpc2submV0L3RlbmFudCI6ImRhdGFyaXNrIiwiaHR0cHM6Ly9uZW9tYXJpbC5kYXRhcmlzay5uZXQvdGVuYW50LWFjdGl2ZSI6dHJ1ZSwiaHR0cHM6Ly9uZW9tYXJpbC5kYXRhcmlzay5uZXQvdXNlci1hY3RpdmUiOnRydWUsImh0dHBzOi8vbmVvbWFyaWwuZGF0YXJpc2submV0L3JvbGUiOiJtYXN0ZXIiLCJpc3MiOiJodHRwczovL2Rldi1tazNvN2xhenhsZTMwaHdxLnVzLmF1dGgwLmNvbS8iLCJzdWIiOiJhdXRoMHw2NTY0Y2M0NTlkYzAzODhlNDVlMDQzZTciLCJhdWQiOlsiaHR0cHM6Ly9kZXYtbWszbzdsYXp4bGUzMGh3cS51cy5hdXRoMC5jb20vYXBpL3YyLyIsImh0dHBzOi8vZGV2LW1rM283bGF6eGxlMzBod3EudXMuYXV0aDAuY29tL3VzZXJpbmZvIl0sImlhdCI6MTcyOTE5NDQ0MiwiZXhwIjoxNzI5MjA1MjQyLCJzY29wZSI6Im9wZW5pZCBwcm9maWxlIGVtYWlsIGFkZHJlc3MgcGhvbmUgcmVhZDpjdXJyZW50X3VzZXIgdXBkYXRlOmN1cnJlbnRfdXNlcl9tZXRhZGF0YSBkZWxldGU6Y3VycmVudF91c2VyX21ldGFkYXRhIGNyZWF0ZTpjdXJyZW50X3VzZXJfbWV0YWRhdGEgY3JlYXRlOmN1cnJlbnRfdXNlcl9kZXZpY2VfY3JlZGVudGlhbHMgZGVsZXRlOmN1cnJlbnRfdXNlcl9kZXZpY2VfY3JlZGVudGlhbHMgdXBkYXRlOmN1cnJlbnRfdXNlcl9pZGVudGl0aWVzIG9mZmxpbmVfYWNjZXNzIiwiZ3R5IjoicGFzc3dvcmQiLCJhenAiOiJrckI2TWxHdmQ4R0FJQ1l3WE93SVptTkMwWTlUYVBBNyJ9.lA_inD8lMJ5CjDaH2X6j5kLl3G78wA4dg-GGdmOd_WcQexeLWGvsLtV0RXG683w7BcZRRkyrgQdpE0S6EECq0jEuPhgagkcruqEqz7-837l7gNt-FouVGnpp9yLdmgazJ07nTBmqA37XSUdpVUrUp4OAqTK9mnP2TnYHRmP2fJQNhHWAwWZkEbj-4y23dsZAkdmSuZKJn6TJaRJgfMEp00LprLS902IQezodsJup_65uMq_TnAN3mN45J4QQnT6l5j1rh9b06h2dMCajeLaHgBdwJvF3szDQrOIygkOGOUhtZgicTytl3vVEIGBRPmFURMVOa7UpVSqxeNR7zeWRHw\")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Start the client. We are reading the credentials in the NEOMARIL_TOKEN env variable\n",
    "client = NeomarilModelClient()\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NeomarilModel\n",
    "\n",
    "It's where you can use your model after you fetch it with the client (or created a new one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-06T13:47:57.926048Z",
     "start_time": "2024-08-06T13:44:42.255158Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "October 17, 2024 | INFO: __upload_model Model 'Teste notebook Sync' inserted - Hash: \"Mff7de8f7b26455b84383fb15faac06652cca0ef1da145e88b5fdbd9c4bdbb9b\"\n",
      "October 17, 2024 | INFO: __host_model Model host in process - Hash: Mff7de8f7b26455b84383fb15faac06652cca0ef1da145e88b5fdbd9c4bdbb9b\n",
      "Waiting for deploy to be ready............October 17, 2024 | INFO: get_model Model Mff7de8f7b26455b84383fb15faac06652cca0ef1da145e88b5fdbd9c4bdbb9b its deployed. Fetching model.\n",
      "October 17, 2024 | INFO: __init__ Loading .env\n",
      "October 17, 2024 | INFO: __init__ Successfully connected to Neomaril\n"
     ]
    }
   ],
   "source": [
    "# Or create a new one\n",
    "\n",
    "PATH = './samples/syncModel/'\n",
    "\n",
    "# Deploying a new model\n",
    "model = client.create_model(\n",
    "    model_name='Teste notebook Sync', # model_name\n",
    "    model_reference='score', # name of the scoring function\n",
    "    source_file=PATH+'app.py', # Path of the source file\n",
    "    model_file=PATH+'model.pkl', # Path of the model pkl file, \n",
    "    requirements_file=PATH+'requirements.txt', # Path of the requirements file, \n",
    "    schema=PATH+'schema.json', # Path of the schema file, but it could be a dict (only required for Sync models)\n",
    "    # env=PATH+'.env'  #  File for env variables (this will be encrypted in the server)\n",
    "    # extra_files=[PATH+'utils.py'], # List with extra files paths that should be uploaded along (they will be all in the same folder)\n",
    "    python_version='3.9', # Can be 3.8 to 3.10\n",
    "    operation=\"Sync\", # Can be Sync or Async\n",
    "    group='test1' # Model group (create one using the client)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-06T13:48:02.978986Z",
     "start_time": "2024-08-06T13:48:02.971439Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeomarilModel(name=\"Teste notebook Sync\", group=\"test1\", \n",
       "                                status=\"Deployed\",\n",
       "                                model_id=\"Mff7de8f7b26455b84383fb15faac06652cca0ef1da145e88b5fdbd9c4bdbb9b\",\n",
       "                                operation=\"Sync\",\n",
       "                                )"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-06T13:48:16.833889Z",
     "start_time": "2024-08-06T13:48:16.829616Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-06 10:48:16.831 | INFO     | neomaril_codex.model:set_token:451 - Token for group groupname added.\n"
     ]
    }
   ],
   "source": [
    "# set group token for this model (you can also add this token in each .predict call or as a env variable NEOMARIL_GROUP_TOKEN)\n",
    "model.set_token('TOKEN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExperimentName: ''\n",
      "Group: test1\n",
      "ModelCreatorUserId: auth0|6564cc459dc0388e45e043e7\n",
      "ModelHash: Mff7de8f7b26455b84383fb15faac06652cca0ef1da145e88b5fdbd9c4bdbb9b\n",
      "ModelReference: score\n",
      "Name: Teste notebook Sync\n",
      "Operation: Sync\n",
      "Origin: External\n",
      "PythonVersion: Python39\n",
      "RunName: ''\n",
      "Status: Deployed\n",
      "TrainingExecution: null\n",
      "TrainingHash: null\n",
      "UploadedAt: '2024-10-17T19:47:25.651502+00:00'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get all information about your model\n",
    "model.model_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-06T13:48:28.646627Z",
     "start_time": "2024-08-06T13:48:24.930781Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Message': 'Model M075d5de742e4d23b5e653a90e704df9fb8c9e28fda24263880d333d94ca6b64 is now disabled.'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Disable your model\n",
    "model.disable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-06T13:48:31.461394Z",
     "start_time": "2024-08-06T13:48:31.458252Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeomarilModel(name=\"Teste notebook Sync\", group=\"groupname\", \n",
       "                                status=\"Disabled\",\n",
       "                                model_id=\"M075d5de742e4d23b5e653a90e704df9fb8c9e28fda24263880d333d94ca6b64\",\n",
       "                                operation=\"Sync\",\n",
       "                                )"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-06T13:48:36.884020Z",
     "start_time": "2024-08-06T13:48:35.011867Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-06 10:48:36.009 | INFO     | neomaril_codex.model:restart_model:268 - Model is restarting\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for deploy to be ready.Model is ready\n"
     ]
    }
   ],
   "source": [
    "# However, remember to restart your model if you wish to use it again\n",
    "model.restart_model(wait_for_ready=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-06T13:49:10.532900Z",
     "start_time": "2024-08-06T13:49:10.529980Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeomarilModel(name=\"Teste notebook Sync\", group=\"groupname\", \n",
       "                                status=\"Deployed\",\n",
       "                                model_id=\"M075d5de742e4d23b5e653a90e704df9fb8c9e28fda24263880d333d94ca6b64\",\n",
       "                                operation=\"Sync\",\n",
       "                                )"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pred': 0, 'proba': 0.0004951423213556372}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "{'pred': 0, 'proba': 0.0004951423213556372}\n"
     ]
    }
   ],
   "source": [
    "# Run predictions with the predict method, or just call it with the model object\n",
    "data = {\n",
    " \"mean_radius\": 17.99,\n",
    " \"mean_texture\": 10.38,\n",
    " \"mean_perimeter\": 122.8,\n",
    " \"mean_area\": 1001.0,\n",
    " \"mean_smoothness\": 0.1184,\n",
    " \"mean_compactness\": 0.2776,\n",
    " \"mean_concavity\": 0.3001,\n",
    " \"mean_concave_points\": 0.1471,\n",
    " \"mean_symmetry\": 0.2419,\n",
    " \"mean_fractal_dimension\": 0.07871,\n",
    " \"radius_error\": 1.095,\n",
    " \"texture_error\": 0.9053,\n",
    " \"perimeter_error\": 8.589,\n",
    " \"area_error\": 153.4,\n",
    " \"smoothness_error\": 0.006399,\n",
    " \"compactness_error\": 0.04904,\n",
    " \"concavity_error\": 0.05373,\n",
    " \"concave_points_error\": 0.01587,\n",
    " \"symmetry_error\": 0.03003,\n",
    " \"fractal_dimension_error\": 0.006193,\n",
    " \"worst_radius\": 25.38,\n",
    " \"worst_texture\": 17.33,\n",
    " \"worst_perimeter\": 184.6,\n",
    " \"worst_area\": 2019.0,\n",
    " \"worst_smoothness\": 0.1622,\n",
    " \"worst_compactness\": 0.6656,\n",
    " \"worst_concavity\": 0.7119,\n",
    " \"worst_concave_points\": 0.2654,\n",
    " \"worst_symmetry\": 0.4601,\n",
    " \"worst_fractal_dimension\": 0.1189\n",
    "}\n",
    "\n",
    "print(model.predict(data=data))\n",
    "print('-'*100)\n",
    "print(model(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:7071/api/model/sync/docs/groupname/M7abe6af98484948ad63f3ad03f25b6496a93f06e23c4ffbaa43eba0f6a1bb91\n",
      "----------------------------------------------------------------------------------------------------\n",
      "curl --request POST \\\n",
      "                    --url http://localhost:7071/api/model/sync/run/groupname/M7abe6af98484948ad63f3ad03f25b6496a93f06e23c4ffbaa43eba0f6a1bb91 \\\n",
      "                    --header 'Authorization: Bearer TOKEN' \\\n",
      "                    --header 'Content-Type: application/json' \\\n",
      "                    --data '{\"Input\": {\"DATA\": \"DATA\"}}'\n",
      "                \n"
     ]
    }
   ],
   "source": [
    "# Serve your model for external clients\n",
    "print(model.docs)\n",
    "print('-'*100)\n",
    "print(model.generate_predict_code(language='curl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-23 10:13:34.993 | INFO     | neomaril_codex.model:register_monitoring:689 - Monitoring created - Hash: \"M7abe6af98484948ad63f3ad03f25b6496a93f06e23c4ffbaa43eba0f6a1bb91\"\n",
      "2024-04-23 10:13:35.223 | INFO     | neomaril_codex.model:__host_monitoring:619 - Model monitoring host started - Hash: \"M7abe6af98484948ad63f3ad03f25b6496a93f06e23c4ffbaa43eba0f6a1bb91\"\n",
      "2024-04-23 10:13:35.549 | INFO     | neomaril_codex.model:__host_monitoring_status:586 - Waiting the monitoring host.\n",
      "2024-04-23 10:14:22.268 | INFO     | neomaril_codex.model:__host_monitoring_status:586 - Waiting the monitoring host.\n",
      "2024-04-23 10:14:52.805 | INFO     | neomaril_codex.model:__host_monitoring_status:586 - Waiting the monitoring host.\n",
      "2024-04-23 10:15:23.220 | INFO     | neomaril_codex.model:__host_monitoring_status:586 - Waiting the monitoring host.\n",
      "2024-04-23 10:15:53.575 | INFO     | neomaril_codex.model:__host_monitoring_status:586 - Waiting the monitoring host.\n",
      "2024-04-23 10:16:23.944 | INFO     | neomaril_codex.model:__host_monitoring_status:590 - Model monitoring host validated - Hash: \"M7abe6af98484948ad63f3ad03f25b6496a93f06e23c4ffbaa43eba0f6a1bb91\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'M7abe6af98484948ad63f3ad03f25b6496a93f06e23c4ffbaa43eba0f6a1bb91'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # We can also add a monitoring configuration for the model\n",
    "\n",
    "PATH = './samples/monitoring/'\n",
    "\n",
    "model.register_monitoring(\n",
    "    preprocess_reference='parse', # name of the preprocess function\n",
    "    shap_reference='get_shap', # name of the preprocess function\n",
    "    configuration_file=PATH+'conf.json', # Path of the configuration file, but it could be a dict\n",
    "    preprocess_file=PATH+'preprocess_sync.py', # Path of the preprocess script\n",
    "    requirements_file=PATH+'requirements.txt' # Path of the requirements file                        \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NeomarilAsyncModelExecution\n",
    "We can create async models as well to send bigger data to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-23 10:16:24.987 | INFO     | neomaril_codex.model:__upload_model:1104 - Model 'Teste notebook Async' inserted - Hash: \"Me6ebaa539cb4a738a66fc52fc34b5422a8c6ae3942b4ca1868624cfda964db3\"\n",
      "2024-04-23 10:16:25.231 | INFO     | neomaril_codex.model:__host_model:1135 - Model host in process - Hash: Me6ebaa539cb4a738a66fc52fc34b5422a8c6ae3942b4ca1868624cfda964db3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for deploy to be ready..........."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-23 10:18:09.812 | INFO     | neomaril_codex.model:get_model:907 - Model Me6ebaa539cb4a738a66fc52fc34b5422a8c6ae3942b4ca1868624cfda964db3 its deployed. Fetching model.\n",
      "2024-04-23 10:18:09.814 | INFO     | neomaril_codex.base:__init__:20 - Loading .env\n",
      "2024-04-23 10:18:09.819 | INFO     | neomaril_codex.base:__init__:31 - Successfully connected to Neomaril\n"
     ]
    }
   ],
   "source": [
    "PATH = './samples/asyncModel/'\n",
    "\n",
    "# Deploying a new model\n",
    "model = client.create_model(\n",
    "    model_name='Teste notebook Async', # model_name\n",
    "    model_reference='score', # name of the scoring function\n",
    "    source_file=PATH+'app.py', # Path of the source file\n",
    "    model_file=PATH+'model.pkl', # Path of the model pkl file, \n",
    "    requirements_file=PATH+'requirements.txt', # Path of the requirements file, \n",
    "    schema=PATH+'schema.csv', # Path of the schema file, but it could be a dict (only required for Sync models)\n",
    "    # env=PATH+'.env'  #  File for env variables (this will be encrypted in the server)\n",
    "    # extra_files=[PATH+'utils.py'], # List with extra files paths that should be uploaded along (they will be all in the same folder)\n",
    "    python_version='3.9', # Can be 3.8 to 3.10\n",
    "    operation=\"Async\", # Can be Sync or Async\n",
    "    input_type='csv',# Can be json or csv or parquet\n",
    "    group='groupname' # Model group (create one using the client)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-23 10:30:43.446 | INFO     | neomaril_codex.model:predict:367 - Execution '5' started. Use the id to check its status.\n",
      "2024-04-23 10:30:43.448 | INFO     | neomaril_codex.base:__init__:20 - Loading .env\n",
      "2024-04-23 10:30:46.321 | INFO     | neomaril_codex.base:__init__:31 - Successfully connected to Neomaril\n",
      "2024-04-23 10:30:46.324 | INFO     | neomaril_codex.base:__init__:279 - Loading .env\n"
     ]
    }
   ],
   "source": [
    "PATH = './samples/asyncModel/'\n",
    "execution = model.predict(data=PATH+'input.csv', group_token='TOKEN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ModelHash': 'Me6ebaa539cb4a738a66fc52fc34b5422a8c6ae3942b4ca1868624cfda964db3',\n",
       " 'Operation': 'Async',\n",
       " 'PythonVersion': 'Python39',\n",
       " 'Status': 'Deployed',\n",
       " 'Name': 'Teste notebook Async',\n",
       " 'Group': 'groupname',\n",
       " 'UploadedAt': '2024-04-23T13:16:24.977421+00:00',\n",
       " 'ExecutionId': 5,\n",
       " 'RunAt': '2024-04-23T13:30:42.970685+00:00',\n",
       " 'ExecutionState': 'Running',\n",
       " 'ExperimentName': '',\n",
       " 'InputPayload': {'executionType': 'neomaril-runAsync',\n",
       "  'basePath': '/app/store/datarisk/groupname/Me6ebaa539cb4a738a66fc52fc34b5422a8c6ae3942b4ca1868624cfda964db3',\n",
       "  'neomarilExecutionId': '5',\n",
       "  'tenantUser': 'datarisk',\n",
       "  'defaultEnvVars': {'identifier': 'datarisk/groupname/Me6ebaa539cb4a738a66fc52fc34b5422a8c6ae3942b4ca1868624cfda964db3',\n",
       "   'inputFileName': 'input.csv'}},\n",
       " 'OutputPayload': {'outputMessage': [],\n",
       "  'outputPath': '/app/store/datarisk/groupname/Me6ebaa539cb4a738a66fc52fc34b5422a8c6ae3942b4ca1868624cfda964db3/5/output/5.zip'}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "execution.execution_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ExecutionId': '5', 'Status': 'Running', 'Message': None}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "execution.get_status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-23 10:31:48.131 | INFO     | neomaril_codex.base:download_result:408 - Output saved in ./output.zip\n"
     ]
    }
   ],
   "source": [
    "execution.wait_ready()\n",
    "execution.download_result()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlops-neomaril-codex-48dADUmW",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
