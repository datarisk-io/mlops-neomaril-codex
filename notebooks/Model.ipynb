{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neomaril Models\n",
    "\n",
    "This notebook give a exemple on how to use Neomaril to deploy a ML model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NeomarilModelClient\n",
    "\n",
    "It's where you can manage your models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the client\n",
    "from neomaril_codex.model import NeomarilModelClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO]You are using the test enviroment that will have the data cleaned from time to time. If your model is ready to use change the flag test_enviroment to False[INFO]\n",
      "[INFO]Successfully connected to Neomaril[INFO]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "NeomarilModelClient(enviroment=\"Staging\", version=\"1.0\")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Start the client\n",
    "token='xxxx'\n",
    "\n",
    "client = NeomarilModelClient(token)\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ModelHash': 'bee5d27c910b4d4886a5a8894fa0994590f7cd3a5e1d45e18b00b123acb0d960',\n",
       " 'Operation': 'Sync',\n",
       " 'PythonVersion': 'Python38',\n",
       " 'Status': 'Deployed',\n",
       " 'Name': 'BDC - Demission',\n",
       " 'Group': 'datarisk',\n",
       " 'UploadedAt': '2022-09-06T15:05:07.9702730Z',\n",
       " 'Schema': {'Result': [{'MatchKeys': 'doc{40375721843}',\n",
       "    'BasicData': {'Age': 32},\n",
       "    'Scholarship': {'Level': 'HIGH SCHOOL'},\n",
       "    'FinantialData': {'BIGDATA_V2': 'ACIMA DE 20 SM'},\n",
       "    'CurrentCompanyData': {'BasicData': {'IsMain': True, 'Code': '6209100'},\n",
       "     'ActivityIndicators': {'EmployeesRange': '050 A 099'},\n",
       "     'ExtendedAddresses': {'IsMain': True,\n",
       "      'City': 'CAMPINAS',\n",
       "      'State': 'SP'}}}]}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List existing models\n",
    "model_list = client.search_models(name=\"BDC\", # This runs a LIKE query in the models names. Can search by state or group either.\n",
    "                                  only_deployed=True # Only shows models that are fully deployed\n",
    "                                  )\n",
    "\n",
    "# This method returns a list, checking the first element\n",
    "model_list[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NeomarilModel\n",
    "\n",
    "It's where you can use your model after you fetch it with the client (or created a new one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO]Model bee5d27c910b4d4886a5a8894fa0994590f7cd3a5e1d45e18b00b123acb0d960 its deployed. Fetching model.[INFO]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "NeomarilModel(name=\"BDC - Demission\", group=\"datarisk\", \n",
       "                               status=\"Deployed\", enviroment=\"Staging\"\n",
       "                               model_id=\"bee5d27c910b4d4886a5a8894fa0994590f7cd3a5e1d45e18b00b123acb0d960\",\n",
       "                               operation=\"Sync\",\n",
       "                               schema={\n",
       "  \"Result\": [\n",
       "    {\n",
       "      \"MatchKeys\": \"doc{40375721843}\",\n",
       "      \"BasicData\": {\n",
       "        \"Age\": 32\n",
       "      },\n",
       "      \"Scholarship\": {\n",
       "        \"Level\": \"HIGH SCHOOL\"\n",
       "      },\n",
       "      \"FinantialData\": {\n",
       "        \"BIGDATA_V2\": \"ACIMA DE 20 SM\"\n",
       "      },\n",
       "      \"CurrentCompanyData\": {\n",
       "        \"BasicData\": {\n",
       "          \"IsMain\": true,\n",
       "          \"Code\": \"6209100\"\n",
       "        },\n",
       "        \"ActivityIndicators\": {\n",
       "          \"EmployeesRange\": \"050 A 099\"\n",
       "        },\n",
       "        \"ExtendedAddresses\": {\n",
       "          \"IsMain\": true,\n",
       "          \"City\": \"CAMPINAS\",\n",
       "          \"State\": \"SP\"\n",
       "        }\n",
       "      }\n",
       "    }\n",
       "  ]\n",
       "}\n",
       "                               )"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gets a existing model from its hash and set group token\n",
    "client.get_model('bee5d27c910b4d4886a5a8894fa0994590f7cd3a5e1d45e18b00b123acb0d960', group_token='xxxx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO]Group not informed, using default 'datarisk' group[INFO]\n",
      "[INFO]Model 'Teste notebook Sync' inserted - Hash: \"M13b5f529ad547309e9ac7e14d5abe9510c6edd91e2b41ae86ffcd272077841e\"[INFO]\n",
      "[INFO]Model host in process - Hash: M13b5f529ad547309e9ac7e14d5abe9510c6edd91e2b41ae86ffcd272077841e[INFO]\n",
      "Wating for deploy to be ready......................................[INFO]Model M13b5f529ad547309e9ac7e14d5abe9510c6edd91e2b41ae86ffcd272077841e its deployed. Fetching model.[INFO]\n"
     ]
    }
   ],
   "source": [
    "# Or create a new one\n",
    "\n",
    "PATH = './samples/syncModel/'\n",
    "\n",
    "# Deploying a new model\n",
    "model = client.create_model('Teste notebook Sync', # model_name\n",
    "                            'score', # name of the scoring function\n",
    "                            PATH+'app.py', # Path of the source file\n",
    "                            PATH+'model.pkl', # Path of the model pkl file, \n",
    "                            PATH+'requirements.txt', # Path of the requirements file, \n",
    "                            PATH+'schema.json', # Path of the schema file, but it could be a dict\n",
    "#                           env=PATH+'.env'  #  File for env variables (this will be encrypted in the server)\n",
    "#                           extra_files=[PATH+'utils.py'], # List with extra files paths that should be uploaded along (they will be all in the same folder)\n",
    "                            python_version='3.9', # Can be 3.7 to 3.10\n",
    "                            operation=\"Sync\" # Can be Sync or Async\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO]Model M13b5f529ad547309e9ac7e14d5abe9510c6edd91e2b41ae86ffcd272077841e its deployed. Fetching model.[INFO]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "NeomarilModel(name=\"Teste notebook Sync\", group=\"datarisk\", \n",
       "                               status=\"Deployed\", enviroment=\"Staging\"\n",
       "                               model_id=\"M13b5f529ad547309e9ac7e14d5abe9510c6edd91e2b41ae86ffcd272077841e\",\n",
       "                               operation=\"Sync\",\n",
       "                               schema={\n",
       "  \"mean radius\": 17.99,\n",
       "  \"mean texture\": 10.38,\n",
       "  \"mean perimeter\": 122.8,\n",
       "  \"mean area\": 1001.0,\n",
       "  \"mean smoothness\": 0.1184,\n",
       "  \"mean compactness\": 0.2776,\n",
       "  \"mean concavity\": 0.3001,\n",
       "  \"mean concave points\": 0.1471,\n",
       "  \"mean symmetry\": 0.2419,\n",
       "  \"mean fractal dimension\": 0.07871,\n",
       "  \"radius error\": 1.095,\n",
       "  \"texture error\": 0.9053,\n",
       "  \"perimeter error\": 8.589,\n",
       "  \"area error\": 153.4,\n",
       "  \"smoothness error\": 0.006399,\n",
       "  \"compactness error\": 0.04904,\n",
       "  \"concavity error\": 0.05373,\n",
       "  \"concave points error\": 0.01587,\n",
       "  \"symmetry error\": 0.03003,\n",
       "  \"fractal dimension error\": 0.006193,\n",
       "  \"worst radius\": 25.38,\n",
       "  \"worst texture\": 17.33,\n",
       "  \"worst perimeter\": 184.6,\n",
       "  \"worst area\": 2019.0,\n",
       "  \"worst smoothness\": 0.1622,\n",
       "  \"worst compactness\": 0.6656,\n",
       "  \"worst concavity\": 0.7119,\n",
       "  \"worst concave points\": 0.2654,\n",
       "  \"worst symmetry\": 0.4601,\n",
       "  \"worst fractal dimension\": 0.1189\n",
       "}\n",
       "                               )"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO]Token for group datarisk added.[INFO]\n"
     ]
    }
   ],
   "source": [
    "# set group token for this model (you can also add this token in each .predict call)\n",
    "model.set_token('xxxx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ModelHash': 'M13b5f529ad547309e9ac7e14d5abe9510c6edd91e2b41ae86ffcd272077841e', 'Operation': 'Sync', 'PythonVersion': 'Python39', 'Status': 'Deployed', 'Name': 'Teste notebook Sync', 'Group': 'datarisk', 'UploadedAt': '2022-11-14T14:21:19.0769760Z', 'Schema': '{\\n  \"mean radius\": 17.99,\\n  \"mean texture\": 10.38,\\n  \"mean perimeter\": 122.8,\\n  \"mean area\": 1001.0,\\n  \"mean smoothness\": 0.1184,\\n  \"mean compactness\": 0.2776,\\n  \"mean concavity\": 0.3001,\\n  \"mean concave points\": 0.1471,\\n  \"mean symmetry\": 0.2419,\\n  \"mean fractal dimension\": 0.07871,\\n  \"radius error\": 1.095,\\n  \"texture error\": 0.9053,\\n  \"perimeter error\": 8.589,\\n  \"area error\": 153.4,\\n  \"smoothness error\": 0.006399,\\n  \"compactness error\": 0.04904,\\n  \"concavity error\": 0.05373,\\n  \"concave points error\": 0.01587,\\n  \"symmetry error\": 0.03003,\\n  \"fractal dimension error\": 0.006193,\\n  \"worst radius\": 25.38,\\n  \"worst texture\": 17.33,\\n  \"worst perimeter\": 184.6,\\n  \"worst area\": 2019.0,\\n  \"worst smoothness\": 0.1622,\\n  \"worst compactness\": 0.6656,\\n  \"worst concavity\": 0.7119,\\n  \"worst concave points\": 0.2654,\\n  \"worst symmetry\": 0.4601,\\n  \"worst fractal dimension\": 0.1189\\n}'}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Teste notebook Sync\n",
      "----------------------------------------------------------------------------------------------------\n",
      "{\n",
      "  \"mean radius\": 17.99,\n",
      "  \"mean texture\": 10.38,\n",
      "  \"mean perimeter\": 122.8,\n",
      "  \"mean area\": 1001.0,\n",
      "  \"mean smoothness\": 0.1184,\n",
      "  \"mean compactness\": 0.2776,\n",
      "  \"mean concavity\": 0.3001,\n",
      "  \"mean concave points\": 0.1471,\n",
      "  \"mean symmetry\": 0.2419,\n",
      "  \"mean fractal dimension\": 0.07871,\n",
      "  \"radius error\": 1.095,\n",
      "  \"texture error\": 0.9053,\n",
      "  \"perimeter error\": 8.589,\n",
      "  \"area error\": 153.4,\n",
      "  \"smoothness error\": 0.006399,\n",
      "  \"compactness error\": 0.04904,\n",
      "  \"concavity error\": 0.05373,\n",
      "  \"concave points error\": 0.01587,\n",
      "  \"symmetry error\": 0.03003,\n",
      "  \"fractal dimension error\": 0.006193,\n",
      "  \"worst radius\": 25.38,\n",
      "  \"worst texture\": 17.33,\n",
      "  \"worst perimeter\": 184.6,\n",
      "  \"worst area\": 2019.0,\n",
      "  \"worst smoothness\": 0.1622,\n",
      "  \"worst compactness\": 0.6656,\n",
      "  \"worst concavity\": 0.7119,\n",
      "  \"worst concave points\": 0.2654,\n",
      "  \"worst symmetry\": 0.4601,\n",
      "  \"worst fractal dimension\": 0.1189\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# All the information about the model can be acessed\n",
    "print(model.model_data)\n",
    "print('-'*100)\n",
    "print(model.name)\n",
    "print('-'*100)\n",
    "print(model.schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 994.1589371301234}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "{'score': 994.1589371301234}\n"
     ]
    }
   ],
   "source": [
    "# Run predictions with the predict method, or just call it with the model object\n",
    "print(model.predict(model.schema))\n",
    "print('-'*100)\n",
    "print(model(model.schema))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO]Monitoring created - Hash: \"M13b5f529ad547309e9ac7e14d5abe9510c6edd91e2b41ae86ffcd272077841e\"[INFO]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'M13b5f529ad547309e9ac7e14d5abe9510c6edd91e2b41ae86ffcd272077841e'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can also add a monitoring configuration for the model\n",
    "\n",
    "PATH = './samples/monitoring/'\n",
    "\n",
    "model.register_monitoring('parse', # name of the preprocess function\n",
    "                          'get_shap', # name of the preprocess function\n",
    "                          configuration_file=PATH+'configuration.json', # Path of the configuration file, but it could be a dict\n",
    "                          preprocess_file=PATH+'preprocess.py', # Path of the preprocess script\n",
    "                          requirements_file=PATH+'requirements.txt' # Path of the requirements file                        \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NeomarilAsyncModelExecution\n",
    "We can create async models as well to send bigger data to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO]Group not informed, using default 'datarisk' group[INFO]\n",
      "[INFO]Model 'Teste notebook Async' inserted - Hash: \"M945953168bd47ef8f015f12560a42ab28a3ac2a94074cae9b0545c22d9136e0\"[INFO]\n",
      "[INFO]Model host in process - Hash: M945953168bd47ef8f015f12560a42ab28a3ac2a94074cae9b0545c22d9136e0[INFO]\n",
      "Wating for deploy to be ready.........[INFO]Model M945953168bd47ef8f015f12560a42ab28a3ac2a94074cae9b0545c22d9136e0 its deployed. Fetching model.[INFO]\n"
     ]
    }
   ],
   "source": [
    "PATH = './samples/asyncModel/'\n",
    "\n",
    "# Deploying a new model\n",
    "model = client.create_model('Teste notebook Async', # model_name\n",
    "                            'score', # name of the scoring function\n",
    "                            PATH+'app.py', # Path of the source file\n",
    "                            PATH+'model.pkl', # Path of the model pkl file, \n",
    "                            PATH+'requirements.txt', # Path of the requirements file, \n",
    "#                           env=PATH+'.env'  #  File for env variables (this will be encrypted in the server)\n",
    "#                           extra_files=[PATH+'utils.py'], # List with extra files paths that should be uploaded along (they will be all in the same folder)\n",
    "                            python_version='3.9', # Can be 3.7 to 3.10\n",
    "                            operation=\"Async\", # Can be Sync or Async\n",
    "                            input_type='csv'# Can be json or csv or parquet\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO]Model M945953168bd47ef8f015f12560a42ab28a3ac2a94074cae9b0545c22d9136e0 its deployed. Fetching model.[INFO]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "NeomarilModel(name=\"Teste notebook Async\", group=\"datarisk\", \n",
       "                               status=\"Deployed\", enviroment=\"Staging\"\n",
       "                               model_id=\"M945953168bd47ef8f015f12560a42ab28a3ac2a94074cae9b0545c22d9136e0\",\n",
       "                               operation=\"Async\",\n",
       "                               schema={}\n",
       "                               )"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO]{\"Message\":\"Execution 3 started. Use the id to check its status.\"}[INFO]\n"
     ]
    }
   ],
   "source": [
    "execution = model.predict(PATH+'input.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeomarilAsyncModelExecution(exec_id=\"3\", status=\"Succeeded\")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'modelExecutionId': '3', 'Status': 'Succeeded'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "execution.get_status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO]Output saved in ./output_3.zip[INFO]\n"
     ]
    }
   ],
   "source": [
    "execution.download_result()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
