{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neomaril Training\n",
    "\n",
    "This notebook give a exemple on how to use Neomaril to training a ML model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NeomarilTrainingClient\n",
    "\n",
    "It's where you can manage your trainining experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-27T12:28:38.913416Z",
     "start_time": "2024-08-27T12:28:38.470234Z"
    }
   },
   "outputs": [],
   "source": [
    "from neomaril_codex.training import NeomarilTrainingClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-27T13:20:58.562764Z",
     "start_time": "2024-08-27T13:18:40.119319Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "October 17, 2024 | INFO: __init__ Loading .env\n",
      "October 17, 2024 | INFO: __init__ Successfully connected to Neomaril\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "API version 1.0 - NeomarilTrainingClient(url=\"http://localhost:7070/api\", Token=\"eyJhbGciOiJSUzI1NiIsInR5cCI6IkpXVCIsImtpZCI6IlFnc0JWQ0I5WFc0V1YtSkVCVkJiZyJ9.eyJodHRwczovL25lb21hcmlsLmRhdGFyaXNrLm5ldC9uZW9tYXJpbC1ncm91cCI6ImRhdGFyaXNrIiwiaHR0cHM6Ly9uZW9tYXJpbC5kYXRhcmlzay5uZXQvZW1haWwiOiJuZW9tYXJpbC1jaUBkYXRhcmlzay5pbyIsImh0dHBzOi8vbmVvbWFyaWwuZGF0YXJpc2submV0L3RlbmFudCI6ImRhdGFyaXNrIiwiaHR0cHM6Ly9uZW9tYXJpbC5kYXRhcmlzay5uZXQvdGVuYW50LWFjdGl2ZSI6dHJ1ZSwiaHR0cHM6Ly9uZW9tYXJpbC5kYXRhcmlzay5uZXQvdXNlci1hY3RpdmUiOnRydWUsImh0dHBzOi8vbmVvbWFyaWwuZGF0YXJpc2submV0L3JvbGUiOiJtYXN0ZXIiLCJpc3MiOiJodHRwczovL2Rldi1tazNvN2xhenhsZTMwaHdxLnVzLmF1dGgwLmNvbS8iLCJzdWIiOiJhdXRoMHw2NTY0Y2M0NTlkYzAzODhlNDVlMDQzZTciLCJhdWQiOlsiaHR0cHM6Ly9kZXYtbWszbzdsYXp4bGUzMGh3cS51cy5hdXRoMC5jb20vYXBpL3YyLyIsImh0dHBzOi8vZGV2LW1rM283bGF6eGxlMzBod3EudXMuYXV0aDAuY29tL3VzZXJpbmZvIl0sImlhdCI6MTcyOTE5NDY3NywiZXhwIjoxNzI5MjA1NDc3LCJzY29wZSI6Im9wZW5pZCBwcm9maWxlIGVtYWlsIGFkZHJlc3MgcGhvbmUgcmVhZDpjdXJyZW50X3VzZXIgdXBkYXRlOmN1cnJlbnRfdXNlcl9tZXRhZGF0YSBkZWxldGU6Y3VycmVudF91c2VyX21ldGFkYXRhIGNyZWF0ZTpjdXJyZW50X3VzZXJfbWV0YWRhdGEgY3JlYXRlOmN1cnJlbnRfdXNlcl9kZXZpY2VfY3JlZGVudGlhbHMgZGVsZXRlOmN1cnJlbnRfdXNlcl9kZXZpY2VfY3JlZGVudGlhbHMgdXBkYXRlOmN1cnJlbnRfdXNlcl9pZGVudGl0aWVzIG9mZmxpbmVfYWNjZXNzIiwiZ3R5IjoicGFzc3dvcmQiLCJhenAiOiJrckI2TWxHdmQ4R0FJQ1l3WE93SVptTkMwWTlUYVBBNyJ9.d2OYwu7XVkBuyDAhRRnIabjsUNsUOxEFUafhGR2pGaxWbEN3pxBjrRdezoxyPB-Rj3U3mmphe25bu1kGDjWw-GfhN0v6y4-onRDNtKAgHidkl9DeJseNHe9zZE5z9fhjqU5M16isf5l5RrpWSBPLOEFJ8kZ-G5ynd6AfuBLIkwpwKOZgbbaRXp8TznpiSdGcJuHTzVDM3tRaDt50_U3vKNxg2UpFaALpUjAujw3PG0pwrttTgsETNuL8Lozd8aGHL2p60nTLatQOZamb8yR-DtljUfbM333IdsWn0tT5xCCwsec3tpSkXj-TZHv04AAn1QKrjF5cl7Z8AHZhig3v0g\")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Start the client. We are reading the credentials in the NEOMARIL_TOKEN env variable\n",
    "\n",
    "client = NeomarilTrainingClient()\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NeomarilTrainingExperiment\n",
    "\n",
    "It's where you can create a training experiment to find the best model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Custom training\n",
    "\n",
    "With Custom training, you have to create the training function. For you, as a data scientist, it's common to re-run the entire notebook, over and over. To avoid creating the same experiment repeatedly, the `force = False` parameter will disallow it. If you wish to create a new experiment with the same attributes, turn `force = True`.\n",
    "\n",
    "If you have two equal experiments and pass `force = False`, the first created experiment will be chosen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "October 17, 2024 | INFO: create_training_experiment Trying to load experiment...\n",
      "October 17, 2024 | INFO: create_training_experiment Could not find experiment. Creating a new one...\n",
      "October 17, 2024 | INFO: __create New Training 'Teste notebook' inserted.\n",
      "October 17, 2024 | INFO: __init__ Loading .env\n",
      "October 17, 2024 | INFO: __init__ Successfully connected to Neomaril\n"
     ]
    }
   ],
   "source": [
    "# Creating a new training experiment\n",
    "training = client.create_training_experiment(\n",
    "    experiment_name='Teste notebook',   # Experiment name, this is how you find your model in MLFLow\n",
    "    model_type='Classification',        # Model type. Can be Classification, Regression or Unsupervised\n",
    "    group='test1',                  # This is the default group. Create a new one when using for a new project,\n",
    "    # force=True                        # Forces to create a new experiment with the same attributes\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeomarilTrainingExperiment(name=\"Teste notebook\", \n",
       "                                                        group=\"test1\", \n",
       "                                                        training_id=\"T240e260811942339393afdf4bf06dbaf66b22c5862c4103b241181ebc2e9dcd\",\n",
       "                                                        model_type=Classification\n",
       "                                                        )"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "October 17, 2024 | INFO: __upload_training Result\n",
      "ExecutionId: 12\n",
      "Message: Training files have been uploaded! Use the id '12' to execute the train experiment.\n",
      "\n",
      "October 17, 2024 | INFO: __execute_training Model training starting - Hash: T240e260811942339393afdf4bf06dbaf66b22c5862c4103b241181ebc2e9dcd\n",
      "October 17, 2024 | INFO: __init__ Loading .env\n",
      "October 17, 2024 | INFO: __init__ Successfully connected to Neomaril\n",
      "October 17, 2024 | INFO: __init__ Loading .env\n",
      "Waiting the training run........"
     ]
    }
   ],
   "source": [
    "# With the experiment class we can create multiple model runs\n",
    "PATH = './samples/train/'\n",
    "\n",
    "run = training.run_training(\n",
    "    run_name='First test', # Run name\n",
    "    train_data=PATH+'dados.csv', # Path to the file with training data\n",
    "    source_file=PATH+'app.py', # Path of the source file\n",
    "    requirements_file=PATH+'requirements.txt', # Path of the requirements file, \n",
    "    # env=PATH+'.env'  #  File for env variables (this will be encrypted in the server)\n",
    "    # extra_files=[PATH+'utils.py'], # List with extra files paths that should be uploaded along (they will be all in the same folder)\n",
    "    training_reference='train_model', # The name of the entrypoint function that is going to be called inside the source file \n",
    "    training_type='Custom',\n",
    "    python_version='3.9', # Can be 3.8 to 3.10\n",
    "    wait_complete=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ExecutionId': '12',\n",
       " 'Status': 'Succeeded',\n",
       " 'Message': 'Training succeeded, successfully generated artifacts.'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run.get_status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deployable: true\n",
      "Description: ''\n",
      "ExecutionId: 12\n",
      "ExecutionState: Succeeded\n",
      "ExperimentName: Teste notebook\n",
      "GroupName: test1\n",
      "ModelType: Classification\n",
      "RunAt: '2024-10-17T19:52:03.647118+00:00'\n",
      "RunData:\n",
      "  outputPath: /app/store/datarisk/test1/T240e260811942339393afdf4bf06dbaf66b22c5862c4103b241181ebc2e9dcd/12/output/12.zip\n",
      "  paramsAndMetrics:\n",
      "    metrics:\n",
      "      auc: 0.9926209713058715\n",
      "      f1_score: 0.9761809612166342\n",
      "      training_accuracy_score: 1.0\n",
      "      training_f1_score: 1.0\n",
      "      training_log_loss: 0.00047178298806016674\n",
      "      training_precision_score: 1.0\n",
      "      training_recall_score: 1.0\n",
      "      training_roc_auc: 1.0\n",
      "      training_score: 1.0\n",
      "    parameters:\n",
      "      cols_with_missing: '0'\n",
      "      lgbmclassifier: LGBMClassifier()\n",
      "      lgbmclassifier__boosting_type: gbdt\n",
      "      lgbmclassifier__class_weight: None\n",
      "      lgbmclassifier__colsample_bytree: '1.0'\n",
      "      lgbmclassifier__importance_type: split\n",
      "      lgbmclassifier__learning_rate: '0.1'\n",
      "      lgbmclassifier__max_depth: '-1'\n",
      "      lgbmclassifier__min_child_samples: '20'\n",
      "      lgbmclassifier__min_child_weight: '0.001'\n",
      "      lgbmclassifier__min_split_gain: '0.0'\n",
      "      lgbmclassifier__n_estimators: '100'\n",
      "      lgbmclassifier__n_jobs: '-1'\n",
      "      lgbmclassifier__num_leaves: '31'\n",
      "      lgbmclassifier__objective: None\n",
      "      lgbmclassifier__random_state: None\n",
      "      lgbmclassifier__reg_alpha: '0.0'\n",
      "      lgbmclassifier__reg_lambda: '0.0'\n",
      "      lgbmclassifier__silent: warn\n",
      "      lgbmclassifier__subsample: '1.0'\n",
      "      lgbmclassifier__subsample_for_bin: '200000'\n",
      "      lgbmclassifier__subsample_freq: '0'\n",
      "      memory: None\n",
      "      missing_distribution: '{''mean_missings'': 0.0, ''min_missings'': 0.0, ''25%_missings'':\n",
      "        0.0, ''50%_missings'': 0.0, ''75%_missings'': 0.0, ''max_missings'': 0.0}'\n",
      "      neomaril_exectuion_id: '12'\n",
      "      shape: (569, 30)\n",
      "      simpleimputer: SimpleImputer()\n",
      "      simpleimputer__add_indicator: 'False'\n",
      "      simpleimputer__copy: 'True'\n",
      "      simpleimputer__fill_value: None\n",
      "      simpleimputer__keep_empty_features: 'False'\n",
      "      simpleimputer__missing_values: nan\n",
      "      simpleimputer__strategy: mean\n",
      "      steps: '[(''simpleimputer'', SimpleImputer()), (''lgbmclassifier'', LGBMClassifier())]'\n",
      "      target_proportion: '{(1,): 0.6274165202108963, (0,): 0.37258347978910367}'\n",
      "      verbose: 'False'\n",
      "RunName: First test\n",
      "TimeElapsed: 187387\n",
      "TrainingHash: T240e260811942339393afdf4bf06dbaf66b22c5862c4103b241181ebc2e9dcd\n",
      "TrainingType: Custom\n",
      "UserId: auth0|6564cc459dc0388e45e043e7\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run.execution_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-22 17:32:50.098 | INFO     | neomaril_codex.base:download_result:408 - Output saved in ./output.zip\n"
     ]
    }
   ],
   "source": [
    "# When the run is finished you can download the model file\n",
    "run.download_result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-22 17:32:50.290 | INFO     | neomaril_codex.training:__upload_model:492 - Model 'Teste notebook promoted custom' promoted from T508b769c7ca49a4a5e60d96fab003cace7533032858439f9b584cc026be02e1 - Hash: \"Md68e3180ce2498cbfb88ca59b6c94ddec7eebc47dac4c9591e34ea88d191b04\"\n",
      "2024-04-22 17:32:52.204 | INFO     | neomaril_codex.training:__host_model:557 - Model host in process - Hash: Md68e3180ce2498cbfb88ca59b6c94ddec7eebc47dac4c9591e34ea88d191b04\n",
      "2024-04-22 17:32:52.206 | INFO     | neomaril_codex.base:__init__:20 - Loading .env\n",
      "2024-04-22 17:32:52.211 | INFO     | neomaril_codex.base:__init__:31 - Successfully connected to Neomaril\n"
     ]
    }
   ],
   "source": [
    "# or promote promete it to a deployed model\n",
    "\n",
    "PATH = './samples/syncModel/'\n",
    "\n",
    "model = run.promote_model(\n",
    "    model_name='Teste notebook promoted custom', # model_name\n",
    "    model_reference='score', # name of the scoring function\n",
    "    source_file=PATH+'app.py', # Path of the source file\n",
    "    schema=PATH+'schema.json', # Path of the schema file, but it could be a dict\n",
    "    # env=PATH+'.env'  #  File for env variables (this will be encrypted in the server)\n",
    "    # extra_files=[PATH+'utils.py'], # List with extra files paths that should be uploaded along (they will be all in the same folder)\n",
    "    operation=\"Sync\" # Can be Sync or Async\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeomarilModel(name=\"Teste notebook promoted custom\", group=\"groupname\", \n",
       "                                status=\"Building\",\n",
       "                                model_id=\"Md68e3180ce2498cbfb88ca59b6c94ddec7eebc47dac4c9591e34ea88d191b04\",\n",
       "                                operation=\"Sync\",\n",
       "                                )"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AutoML\n",
    "\n",
    "With AutoML you just need to upload the data and some configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-22 17:33:37.256 | INFO     | neomaril_codex.training:__upload_training:915 - {\"ExecutionId\":2,\"Message\":\"Training files have been uploaded! Use the id \\u00272\\u0027 to execute the train experiment.\"}\n",
      "2024-04-22 17:33:37.419 | INFO     | neomaril_codex.training:__execute_training:939 - Model training starting - Hash: T508b769c7ca49a4a5e60d96fab003cace7533032858439f9b584cc026be02e1\n",
      "2024-04-22 17:33:37.440 | INFO     | neomaril_codex.base:__init__:20 - Loading .env\n",
      "2024-04-22 17:33:37.445 | INFO     | neomaril_codex.base:__init__:31 - Successfully connected to Neomaril\n",
      "2024-04-22 17:33:37.447 | INFO     | neomaril_codex.base:__init__:279 - Loading .env\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting the training run................"
     ]
    }
   ],
   "source": [
    "PATH = './samples/autoML/'\n",
    "\n",
    "run = training.run_training(\n",
    "    run_name='First test', # Run name\n",
    "    training_type='AutoML',\n",
    "    train_data=PATH+'dados.csv', # Path to the file with training data\n",
    "    conf_dict=PATH+'conf.json', # Path of the configuration file\n",
    "    wait_complete=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeomarilTrainingExecution(name=\"First test\",\n",
       "                                        exec_id=\"2\", status=\"Succeeded\")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ExecutionId': '2',\n",
       " 'Status': 'Succeeded',\n",
       " 'Message': 'wasbs://mlflow-dev@datariskmlops.blob.core.windows.net/artifacts/1/250f70714e5d4a6f9fa3b55c6b9aaf43/artifacts'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run.get_status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-22 17:41:28.830 | INFO     | neomaril_codex.training:__upload_model:492 - Model 'Teste notebook promoted autoML' promoted from T508b769c7ca49a4a5e60d96fab003cace7533032858439f9b584cc026be02e1 - Hash: \"M0fa3683553e41c4a1a99290c2451ff190785d06b90646e6afe7ffa352c00193\"\n",
      "2024-04-22 17:41:29.135 | INFO     | neomaril_codex.training:__host_model:557 - Model host in process - Hash: M0fa3683553e41c4a1a99290c2451ff190785d06b90646e6afe7ffa352c00193\n",
      "2024-04-22 17:41:29.137 | INFO     | neomaril_codex.base:__init__:20 - Loading .env\n",
      "2024-04-22 17:41:29.140 | INFO     | neomaril_codex.base:__init__:31 - Successfully connected to Neomaril\n"
     ]
    }
   ],
   "source": [
    "# Promote a AutoML model is a lot easier\n",
    "\n",
    "PATH = './samples/autoML/'\n",
    "MODEL_PATH = './samples/syncModel/'\n",
    "\n",
    "model = run.promote_model(\n",
    "    model_name='Teste notebook promoted autoML', # model_name\n",
    "    operation=\"Async\", # Can be Sync or Async,\n",
    "    input_type=\"json\",\n",
    "    schema=PATH+'schema.json'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeomarilModel(name=\"Teste notebook promoted autoML\", group=\"groupname\", \n",
       "                                status=\"Building\",\n",
       "                                model_id=\"M0fa3683553e41c4a1a99290c2451ff190785d06b90646e6afe7ffa352c00193\",\n",
       "                                operation=\"Async\",\n",
       "                                )"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlops-neomaril-codex-48dADUmW",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
