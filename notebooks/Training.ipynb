{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neomaril Training\n",
    "\n",
    "This notebook give a exemple on how to use Neomaril to training a ML model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NeomarilTrainingClient\n",
    "\n",
    "It's where you can manage your trainining experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the client\n",
    "from neomaril_codex.training import NeomarilTrainingClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-09 12:07:43.720 | INFO     | neomaril_codex.training:__init__:1063 - Loading .env\n",
      "2023-11-09 12:07:43.722 | INFO     | neomaril_codex.base:__init__:90 - Loading .env\n",
      "2023-11-09 12:07:45.565 | INFO     | neomaril_codex.base:__init__:102 - Successfully connected to Neomaril\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "NeomarilTrainingClient(url=\"http://localhost:7070/api\", version=\"eyJhbGciOiJSUzI1NiIsInR5cCI6IkpXVCIsImtpZCI6IlFnc0JWQ0I5WFc0V1YtSkVCVkJiZyJ9.eyJodHRwczovL25lb21hcmlsLmRhdGFyaXNrLm5ldC9uZW9tYXJpbC1ncm91cCI6ImRhdGFyaXNrIiwiaXNzIjoiaHR0cHM6Ly9kZXYtbWszbzdsYXp4bGUzMGh3cS51cy5hdXRoMC5jb20vIiwic3ViIjoiYXV0aDB8NjU0OTRlMWFkOTUzN2FlMGFhZDZjNGE5IiwiYXVkIjpbImh0dHBzOi8vZGV2LW1rM283bGF6eGxlMzBod3EudXMuYXV0aDAuY29tL2FwaS92Mi8iLCJodHRwczovL2Rldi1tazNvN2xhenhsZTMwaHdxLnVzLmF1dGgwLmNvbS91c2VyaW5mbyJdLCJpYXQiOjE2OTk1NDI0NjUsImV4cCI6MTY5OTU1MzI2NSwiYXpwIjoia3JCNk1sR3ZkOEdBSUNZd1hPd0labU5DMFk5VGFQQTciLCJzY29wZSI6Im9wZW5pZCBwcm9maWxlIGVtYWlsIGFkZHJlc3MgcGhvbmUgcmVhZDpjdXJyZW50X3VzZXIgdXBkYXRlOmN1cnJlbnRfdXNlcl9tZXRhZGF0YSBkZWxldGU6Y3VycmVudF91c2VyX21ldGFkYXRhIGNyZWF0ZTpjdXJyZW50X3VzZXJfbWV0YWRhdGEgY3JlYXRlOmN1cnJlbnRfdXNlcl9kZXZpY2VfY3JlZGVudGlhbHMgZGVsZXRlOmN1cnJlbnRfdXNlcl9kZXZpY2VfY3JlZGVudGlhbHMgdXBkYXRlOmN1cnJlbnRfdXNlcl9pZGVudGl0aWVzIG9mZmxpbmVfYWNjZXNzIiwiZ3R5IjoicGFzc3dvcmQifQ.A7LBdPwObV6DkP8GjEkp-m1-RLf_RGWLQkAs-X0GxRyUxGiwjL3mENl5aGhL8M1aNlByMI-O89J00zpu08NyASQiCwXQyO5HbB5qJ2Fut2vEmcspwkMN33_NJBHqAP2yy0OrnfPtcAtkpm5BVD5_heL5x8Z29KBMN-RUS1Hb9aG9vDNkLij7qAssvqROqFhfPoJFsY1JSPDanCi5BskiMCMp6OQdIgFsWiiSZGdatnoBhz91wVtNR4Akd03UxnjffhyqkLBe2QeCYCRsxQhdgl5FCP1JbsuhlelYWN_b7EailwgK4pkdqV5O2uRO0HDLgpOJ958002JKeaFB_YWatA\")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Start the client. We are reading the credentials in the NEOMARIL_TOKEN env variable\n",
    "\n",
    "client = NeomarilTrainingClient()\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NeomarilTrainingExperiment\n",
    "\n",
    "It's where you can create a training experiment to find the best model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Custom training\n",
    "\n",
    "With Custom training you have to create the training function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-09 12:07:45.604 | INFO     | neomaril_codex.training:create_training_experiment:1164 - New Training 'Teste notebook Training custom' inserted.\n",
      "2023-11-09 12:07:45.606 | INFO     | neomaril_codex.training:__init__:611 - Loading .env\n"
     ]
    }
   ],
   "source": [
    "# Creating a new training experiment\n",
    "training = client.create_training_experiment('Teste notebook Training custom', # Experiment name, this is how you find your model in MLFLow\n",
    "                                            'Classification', # Model type. Can be Classification, Regression or Unsupervised\n",
    "                                            group='datarisk' # This is the default group. Create a new one when using for a new project\n",
    "                                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeomarilTrainingExperiment(name=\"Teste notebook Training custom\", \n",
       "                                                        group=\"datarisk\", \n",
       "                                                        training_id=\"T2e179e0f66e4c8b9507da56d706c0079c0d2d910b4648b6a6c5e17d7240d6f5\",\n",
       "                                                        model_type=Classification\n",
       "                                                        )"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-09 12:07:45.759 | INFO     | neomaril_codex.training:__execute_training:843 - Model training starting - Hash: T2e179e0f66e4c8b9507da56d706c0079c0d2d910b4648b6a6c5e17d7240d6f5\n",
      "2023-11-09 12:07:45.775 | INFO     | neomaril_codex.base:__init__:279 - Loading .env\n",
      "2023-11-09 12:07:45.806 | INFO     | neomaril_codex.training:__init__:329 - Loading .env\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logger.info({\"ExecutionId\":5,\"Message\":\"Training files have been uploaded! Use the id \\u00275\\u0027 to execute the train experiment.\"}\n",
      "Wating the training run......."
     ]
    }
   ],
   "source": [
    "# With the experiment class we can create multiple model runs\n",
    "PATH = './samples/train/'\n",
    "\n",
    "run = training.run_training('First test', # Run name\n",
    "                            train_data=PATH+'dados.csv', # Path to the file with training data\n",
    "                            source_file=PATH+'app.py', # Path of the source file\n",
    "                            requirements_file=PATH+'requirements.txt', # Path of the requirements file, \n",
    "#                           env=PATH+'.env'  #  File for env variables (this will be encrypted in the server)\n",
    "#                           extra_files=[PATH+'utils.py'], # List with extra files paths that should be uploaded along (they will be all in the same folder)\n",
    "                            training_reference='train_model', # The name of the entrypoint function that is going to be called inside the source file \n",
    "                            training_type='Custom',\n",
    "                            python_version='3.9', # Can be 3.7 to 3.10\n",
    "                            wait_complete=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ExecutionId': '5',\n",
       " 'Status': 'Succeeded',\n",
       " 'Message': 'wasbs://mlflow-dev@datariskmlops.blob.core.windows.net/artifacts/2/9919f2e9a0314ebab75c41e17abd07b9/artifacts'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run.get_status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'TrainingHash': 'T2e179e0f66e4c8b9507da56d706c0079c0d2d910b4648b6a6c5e17d7240d6f5',\n",
       " 'ExperimentName': 'Teste notebook Training custom',\n",
       " 'GroupName': 'datarisk',\n",
       " 'ModelType': 'Classification',\n",
       " 'TrainingType': 'Custom',\n",
       " 'ExecutionId': 5,\n",
       " 'RunName': 'First test',\n",
       " 'ExecutionState': 'Succeeded',\n",
       " 'TimeElapsed': 180229,\n",
       " 'Description': '',\n",
       " 'Deployable': True,\n",
       " 'RunData': {'metrics': [{'key': 'training_precision_score',\n",
       "    'value': 1.0,\n",
       "    'timestamp': 1699542572563,\n",
       "    'step': 0},\n",
       "   {'key': 'training_recall_score',\n",
       "    'value': 1.0,\n",
       "    'timestamp': 1699542572563,\n",
       "    'step': 0},\n",
       "   {'key': 'training_f1_score',\n",
       "    'value': 1.0,\n",
       "    'timestamp': 1699542572563,\n",
       "    'step': 0},\n",
       "   {'key': 'training_accuracy_score',\n",
       "    'value': 1.0,\n",
       "    'timestamp': 1699542572563,\n",
       "    'step': 0},\n",
       "   {'key': 'training_log_loss',\n",
       "    'value': 0.00047178298806016674,\n",
       "    'timestamp': 1699542572563,\n",
       "    'step': 0},\n",
       "   {'key': 'training_roc_auc',\n",
       "    'value': 1.0,\n",
       "    'timestamp': 1699542572563,\n",
       "    'step': 0},\n",
       "   {'key': 'training_score',\n",
       "    'value': 1.0,\n",
       "    'timestamp': 1699542572776,\n",
       "    'step': 0},\n",
       "   {'key': 'f1_score_X_test-6',\n",
       "    'value': 0.9503546099290779,\n",
       "    'timestamp': 1699542570319,\n",
       "    'step': 0},\n",
       "   {'key': 'f1_score-2_X_test-7',\n",
       "    'value': 0.9722222222222222,\n",
       "    'timestamp': 1699542570774,\n",
       "    'step': 0},\n",
       "   {'key': 'f1_score-3_X_test-8',\n",
       "    'value': 0.9863013698630138,\n",
       "    'timestamp': 1699542571271,\n",
       "    'step': 0},\n",
       "   {'key': 'f1_score-4_X_test-9',\n",
       "    'value': 0.9861111111111112,\n",
       "    'timestamp': 1699542571837,\n",
       "    'step': 0},\n",
       "   {'key': 'f1_score-5_X_test-10',\n",
       "    'value': 0.9859154929577465,\n",
       "    'timestamp': 1699542572350,\n",
       "    'step': 0},\n",
       "   {'key': 'auc',\n",
       "    'value': 0.9926209713058715,\n",
       "    'timestamp': 1699542573212,\n",
       "    'step': 0},\n",
       "   {'key': 'f1_score',\n",
       "    'value': 0.9761809612166342,\n",
       "    'timestamp': 1699542573212,\n",
       "    'step': 0}],\n",
       "  'params': [{'key': 'memory', 'value': 'None'},\n",
       "   {'key': 'steps',\n",
       "    'value': \"[('simpleimputer', SimpleImputer()), ('lgbmclassifier', LGBMClassifier())]\"},\n",
       "   {'key': 'verbose', 'value': 'False'},\n",
       "   {'key': 'simpleimputer', 'value': 'SimpleImputer()'},\n",
       "   {'key': 'lgbmclassifier', 'value': 'LGBMClassifier()'},\n",
       "   {'key': 'simpleimputer__add_indicator', 'value': 'False'},\n",
       "   {'key': 'simpleimputer__copy', 'value': 'True'},\n",
       "   {'key': 'simpleimputer__fill_value', 'value': 'None'},\n",
       "   {'key': 'simpleimputer__missing_values', 'value': 'nan'},\n",
       "   {'key': 'simpleimputer__strategy', 'value': 'mean'},\n",
       "   {'key': 'simpleimputer__verbose', 'value': '0'},\n",
       "   {'key': 'lgbmclassifier__boosting_type', 'value': 'gbdt'},\n",
       "   {'key': 'lgbmclassifier__class_weight', 'value': 'None'},\n",
       "   {'key': 'lgbmclassifier__colsample_bytree', 'value': '1.0'},\n",
       "   {'key': 'lgbmclassifier__importance_type', 'value': 'split'},\n",
       "   {'key': 'lgbmclassifier__learning_rate', 'value': '0.1'},\n",
       "   {'key': 'lgbmclassifier__max_depth', 'value': '-1'},\n",
       "   {'key': 'lgbmclassifier__min_child_samples', 'value': '20'},\n",
       "   {'key': 'lgbmclassifier__min_child_weight', 'value': '0.001'},\n",
       "   {'key': 'lgbmclassifier__min_split_gain', 'value': '0.0'},\n",
       "   {'key': 'lgbmclassifier__n_estimators', 'value': '100'},\n",
       "   {'key': 'lgbmclassifier__n_jobs', 'value': '-1'},\n",
       "   {'key': 'lgbmclassifier__num_leaves', 'value': '31'},\n",
       "   {'key': 'lgbmclassifier__objective', 'value': 'None'},\n",
       "   {'key': 'lgbmclassifier__random_state', 'value': 'None'},\n",
       "   {'key': 'lgbmclassifier__reg_alpha', 'value': '0.0'},\n",
       "   {'key': 'lgbmclassifier__reg_lambda', 'value': '0.0'},\n",
       "   {'key': 'lgbmclassifier__silent', 'value': 'warn'},\n",
       "   {'key': 'lgbmclassifier__subsample', 'value': '1.0'},\n",
       "   {'key': 'lgbmclassifier__subsample_for_bin', 'value': '200000'},\n",
       "   {'key': 'lgbmclassifier__subsample_freq', 'value': '0'},\n",
       "   {'key': 'shape', 'value': '(569, 30)'},\n",
       "   {'key': 'cols_with_missing', 'value': '0'},\n",
       "   {'key': 'missing_distribution',\n",
       "    'value': \"{'mean_missings': nan, 'std_missings': nan, 'min_missings': nan, '25%_missings': nan, '50%_missings': nan, '75%_missings': nan, 'max_missings': nan}\"},\n",
       "   {'key': 'neomaril_exectuion_id', 'value': '5'},\n",
       "   {'key': 'target_proportion',\n",
       "    'value': '{(1,): 0.6274165202108963, (0,): 0.37258347978910367}'}],\n",
       "  'mlflow_run_id': '9919f2e9a0314ebab75c41e17abd07b9',\n",
       "  'mlflow_experiment_id': '2'},\n",
       " 'RunAt': '2023-11-09T15:07:45.649001Z'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run.execution_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-09 12:10:48.166 | INFO     | neomaril_codex.base:download_result:413 - Output saved in ./output.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-09 12:10:48.208 | INFO     | neomaril_codex.training:__upload_model:429 - Model 'Teste notebook promoted custom' promoted from T2e179e0f66e4c8b9507da56d706c0079c0d2d910b4648b6a6c5e17d7240d6f5 - Hash: \"Mbe371ff4bfc4f82897619da84c3c004211614c6677d431ca98a251d5da826d5\"\n",
      "2023-11-09 12:10:50.758 | INFO     | neomaril_codex.training:__host_model:494 - Model host in process - Hash: Mbe371ff4bfc4f82897619da84c3c004211614c6677d431ca98a251d5da826d5\n",
      "2023-11-09 12:10:50.760 | INFO     | neomaril_codex.model:__init__:69 - Loading .env\n"
     ]
    }
   ],
   "source": [
    "# When the run is finished you can download the model file\n",
    "run.download_result()\n",
    "\n",
    "# or promote promete it to a deployed model\n",
    "\n",
    "PATH = './samples/syncModel/'\n",
    "\n",
    "model = run.promote_model('Teste notebook promoted custom', # model_name\n",
    "                            'score', # name of the scoring function\n",
    "                            PATH+'app.py', # Path of the source file\n",
    "                            PATH+'schema.json', # Path of the schema file, but it could be a dict\n",
    "#                           env=PATH+'.env'  #  File for env variables (this will be encrypted in the server)\n",
    "#                           extra_files=[PATH+'utils.py'], # List with extra files paths that should be uploaded along (they will be all in the same folder)\n",
    "                            operation=\"Sync\" # Can be Sync or Async\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeomarilModel(name=\"Teste notebook promoted custom\", group=\"datarisk\", \n",
       "                                status=\"Building\",\n",
       "                                model_id=\"Mbe371ff4bfc4f82897619da84c3c004211614c6677d431ca98a251d5da826d5\",\n",
       "                                operation=\"Sync\",\n",
       "                                schema={'mean_radius': 17.99, 'mean_texture': 10.38, 'mean_perimeter': 122.8, 'mean_area': 1001.0, 'mean_smoothness': 0.1184, 'mean_compactness': 0.2776, 'mean_concavity': 0.3001, 'mean_concave_points': 0.1471, 'mean_symmetry': 0.2419, 'mean_fractal_dimension': 0.07871, 'radius_error': 1.095, 'texture_error': 0.9053, 'perimeter_error': 8.589, 'area_error': 153.4, 'smoothness_error': 0.006399, 'compactness_error': 0.04904, 'concavity_error': 0.05373, 'concave_points_error': 0.01587, 'symmetry_error': 0.03003, 'fractal_dimension_error': 0.006193, 'worst_radius': 25.38, 'worst_texture': 17.33, 'worst_perimeter': 184.6, 'worst_area': 2019.0, 'worst_smoothness': 0.1622, 'worst_compactness': 0.6656, 'worst_concavity': 0.7119, 'worst_concave_points': 0.2654, 'worst_symmetry': 0.4601, 'worst_fractal_dimension': 0.1189}\n",
       "                                )"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AutoML\n",
    "\n",
    "With AutoML you just need to upload the data and some configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logger.info({\"ExecutionId\":6,\"Message\":\"Training files have been uploaded! Use the id \\u00276\\u0027 to execute the train experiment.\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-09 12:10:51.104 | INFO     | neomaril_codex.training:__execute_training:843 - Model training starting - Hash: T2e179e0f66e4c8b9507da56d706c0079c0d2d910b4648b6a6c5e17d7240d6f5\n",
      "2023-11-09 12:10:51.120 | INFO     | neomaril_codex.base:__init__:279 - Loading .env\n",
      "2023-11-09 12:10:51.147 | INFO     | neomaril_codex.training:__init__:329 - Loading .env\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wating the training run............."
     ]
    }
   ],
   "source": [
    "PATH = './samples/autoML/'\n",
    "\n",
    "run = training.run_training('First test', # Run name\n",
    "                            training_type='AutoML',\n",
    "                            train_data=PATH+'dados.csv', # Path to the file with training data\n",
    "                            conf_dict=PATH+'conf.json', # Path of the configuration file\n",
    "                            wait_complete=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeomarilTrainingExecution(name=\"Teste notebook Training custom\",\n",
       "                                        exec_id=\"6\", status=\"Succeeded\")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ExecutionId': '6',\n",
       " 'Status': 'Succeeded',\n",
       " 'Message': 'wasbs://mlflow-dev@datariskmlops.blob.core.windows.net/artifacts/2/a9d853a19095410eb3cf4aa5c57613f9/artifacts'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run.get_status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeomarilTrainingExecution(name=\"Teste notebook Training custom\",\n",
       "                                        exec_id=\"6\", status=\"Succeeded\")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-09 12:16:57.717 | INFO     | neomaril_codex.training:__upload_model:429 - Model 'Teste notebook promoted autoML' promoted from T2e179e0f66e4c8b9507da56d706c0079c0d2d910b4648b6a6c5e17d7240d6f5 - Hash: \"Mba250c10ea9408284db84b02f954708e73528a67e3b49a48a04a3b641b3a247\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-09 12:16:57.947 | INFO     | neomaril_codex.training:__host_model:494 - Model host in process - Hash: Mba250c10ea9408284db84b02f954708e73528a67e3b49a48a04a3b641b3a247\n",
      "2023-11-09 12:16:57.949 | INFO     | neomaril_codex.model:__init__:69 - Loading .env\n"
     ]
    }
   ],
   "source": [
    "# Promote a AutoML model is a lot easier\n",
    "\n",
    "PATH = './samples/syncModel/'\n",
    "\n",
    "model = run.promote_model('Teste notebook promoted autoML', # model_name\n",
    "                            operation=\"Async\" # Can be Sync or Async\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeomarilModel(name=\"Teste notebook promoted autoML\", group=\"datarisk\", \n",
       "                                status=\"Building\",\n",
       "                                model_id=\"Mba250c10ea9408284db84b02f954708e73528a67e3b49a48a04a3b641b3a247\",\n",
       "                                operation=\"Async\",\n",
       "                                schema={}\n",
       "                                )"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neomaril-codex-WNTK3WJm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "d7308033b61508a213f02f142180c32f76fea0bd8e107ff2b0f7849d3585655c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
