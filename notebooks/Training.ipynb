{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neomaril Training\n",
    "\n",
    "This notebook give a exemple on how to use Neomaril to training a ML model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NeomarilTrainingClient\n",
    "\n",
    "It's where you can manage your trainining experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the client\n",
    "from neomaril_codex.training import NeomarilTrainingClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-29 10:34:19.211 | INFO     | neomaril_codex.base:__init__:87 - Loading .env\n",
      "2023-05-29 10:34:19.362 | INFO     | neomaril_codex.base:__init__:99 - Successfully connected to Neomaril\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "NeomarilTrainingClient(url=\"http://localhost:7070/api\", version=\"1.0\")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Start the client. We are reading the credentials in the NEOMARIL_TOKEN env variable\n",
    "\n",
    "client = NeomarilTrainingClient()\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NeomarilTrainingExperiment\n",
    "\n",
    "It's where you can create a training experiment to find the best model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Custom training\n",
    "\n",
    "With Custom training you have to create the training function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-29 10:34:20.241 | INFO     | neomaril_codex.training:create_training_experiment:719 - New Training 'Teste notebook Training custom' inserted.\n"
     ]
    }
   ],
   "source": [
    "# Creating a new training experiment\n",
    "training = client.create_training_experiment('Teste notebook Training custom', # Experiment name, this is how you find your model in MLFLow\n",
    "                                            'Classification', # Model type. Can be Classification, Regression or Unsupervised\n",
    "                                            'Custom', # Training type. Can be Custom or AutoML\n",
    "                                            group='datarisk' # This is the default group. Create a new one when using for a new project\n",
    "                                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeomarilTrainingExperiment(name=\"Teste notebook Training custom\", \n",
       "                                                        group=\"datarisk\", \n",
       "                                                        training_id=\"Td2d7ca1a7f84110b25bd81f9429a2d026bf16e58d3a4bf59ef55a0fa101c160\",\n",
       "                                                        training_type=\"Custom\",\n",
       "                                                        model_type=Classification\n",
       "                                                        )"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-29 10:34:20.493 | INFO     | neomaril_codex.training:__upload_training:448 - {\"ExecutionId\":1,\"Message\":\"Training files have been uploaded. Use the execution id '1' to check its status.\"}\n",
      "2023-05-29 10:34:20.958 | INFO     | neomaril_codex.training:__execute_training:472 - Model training starting - Hash: Td2d7ca1a7f84110b25bd81f9429a2d026bf16e58d3a4bf59ef55a0fa101c160\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wating the training run......."
     ]
    }
   ],
   "source": [
    "# With the experiment class we can create multiple model runs\n",
    "PATH = './samples/train/'\n",
    "\n",
    "run = training.run_training('First test', # Run name\n",
    "                            PATH+'dados.csv', # Path to the file with training data\n",
    "                            source_file=PATH+'app.py', # Path of the source file\n",
    "                            requirements_file=PATH+'requirements.txt', # Path of the requirements file, \n",
    "#                           env=PATH+'.env'  #  File for env variables (this will be encrypted in the server)\n",
    "#                           extra_files=[PATH+'utils.py'], # List with extra files paths that should be uploaded along (they will be all in the same folder)\n",
    "                            training_reference='train_model', # The name of the entrypoint function that is going to be called inside the source file \n",
    "                            python_version='3.9', # Can be 3.7 to 3.10\n",
    "                            wait_complete=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'trainingExecutionId': '1',\n",
       " 'Status': 'Succeeded',\n",
       " 'Message': '{\\n    \"artifacts\": \"wasbs://mlflow-dev@datariskmlops.blob.core.windows.net/artifacts/1/7d054f99a84c4baabd2db7305ddcd895/artifacts\",\\n    \"mlflow_run_id\": \"7d054f99a84c4baabd2db7305ddcd895\"\\n}'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run.get_status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'TrainingHash': 'Td2d7ca1a7f84110b25bd81f9429a2d026bf16e58d3a4bf59ef55a0fa101c160',\n",
       " 'ExperimentName': 'Teste notebook Training custom',\n",
       " 'GroupName': 'datarisk',\n",
       " 'ModelType': 'Classification',\n",
       " 'TrainingType': 'Custom',\n",
       " 'ExecutionId': 1,\n",
       " 'ExecutionState': 'Succeeded',\n",
       " 'RunData': {'metrics': [{'key': 'auc',\n",
       "    'value': 0.9938884816218586,\n",
       "    'timestamp': 1685367433767,\n",
       "    'step': 0},\n",
       "   {'key': 'f1_score',\n",
       "    'value': 0.9818934131003096,\n",
       "    'timestamp': 1685367433767,\n",
       "    'step': 0}],\n",
       "  'params': [{'key': 'shape', 'value': '(569, 30)'},\n",
       "   {'key': 'cols_with_missing', 'value': '0'},\n",
       "   {'key': 'missing_distribution',\n",
       "    'value': \"{'mean_missings': nan, 'std_missings': nan, 'min_missings': nan, '25%_missings': nan, '50%_missings': nan, '75%_missings': nan, 'max_missings': nan}\"},\n",
       "   {'key': 'target_proportion',\n",
       "    'value': '{(1,): 0.6274165202108963, (0,): 0.37258347978910367}'},\n",
       "   {'key': 'pipeline_steps', 'value': 'simpleimputer, xgbclassifier'},\n",
       "   {'key': 'hyperparam_simpleimputer__add_indicator', 'value': 'False'},\n",
       "   {'key': 'hyperparam_simpleimputer__copy', 'value': 'True'},\n",
       "   {'key': 'hyperparam_simpleimputer__fill_value', 'value': 'None'},\n",
       "   {'key': 'hyperparam_simpleimputer__missing_values', 'value': 'nan'},\n",
       "   {'key': 'hyperparam_simpleimputer__strategy', 'value': 'mean'},\n",
       "   {'key': 'hyperparam_simpleimputer__verbose', 'value': '0'},\n",
       "   {'key': 'hyperparam_xgbclassifier__objective', 'value': 'binary:logistic'},\n",
       "   {'key': 'hyperparam_xgbclassifier__use_label_encoder', 'value': 'True'},\n",
       "   {'key': 'hyperparam_xgbclassifier__base_score', 'value': '0.5'},\n",
       "   {'key': 'hyperparam_xgbclassifier__booster', 'value': 'gbtree'},\n",
       "   {'key': 'hyperparam_xgbclassifier__colsample_bylevel', 'value': '1'},\n",
       "   {'key': 'hyperparam_xgbclassifier__colsample_bynode', 'value': '1'},\n",
       "   {'key': 'hyperparam_xgbclassifier__colsample_bytree', 'value': '1'},\n",
       "   {'key': 'hyperparam_xgbclassifier__enable_categorical', 'value': 'False'},\n",
       "   {'key': 'hyperparam_xgbclassifier__gamma', 'value': '0'},\n",
       "   {'key': 'hyperparam_xgbclassifier__gpu_id', 'value': '-1'},\n",
       "   {'key': 'hyperparam_xgbclassifier__importance_type', 'value': 'None'},\n",
       "   {'key': 'hyperparam_xgbclassifier__interaction_constraints', 'value': ''},\n",
       "   {'key': 'hyperparam_xgbclassifier__learning_rate', 'value': '0.300000012'},\n",
       "   {'key': 'hyperparam_xgbclassifier__max_delta_step', 'value': '0'},\n",
       "   {'key': 'hyperparam_xgbclassifier__max_depth', 'value': '6'},\n",
       "   {'key': 'hyperparam_xgbclassifier__min_child_weight', 'value': '1'},\n",
       "   {'key': 'hyperparam_xgbclassifier__missing', 'value': 'nan'},\n",
       "   {'key': 'hyperparam_xgbclassifier__monotone_constraints', 'value': '()'},\n",
       "   {'key': 'hyperparam_xgbclassifier__n_estimators', 'value': '100'},\n",
       "   {'key': 'hyperparam_xgbclassifier__n_jobs', 'value': '8'},\n",
       "   {'key': 'hyperparam_xgbclassifier__num_parallel_tree', 'value': '1'},\n",
       "   {'key': 'hyperparam_xgbclassifier__predictor', 'value': 'auto'},\n",
       "   {'key': 'hyperparam_xgbclassifier__random_state', 'value': '0'},\n",
       "   {'key': 'hyperparam_xgbclassifier__reg_alpha', 'value': '0'},\n",
       "   {'key': 'hyperparam_xgbclassifier__reg_lambda', 'value': '1'},\n",
       "   {'key': 'hyperparam_xgbclassifier__scale_pos_weight', 'value': '1'},\n",
       "   {'key': 'hyperparam_xgbclassifier__subsample', 'value': '1'},\n",
       "   {'key': 'hyperparam_xgbclassifier__tree_method', 'value': 'exact'},\n",
       "   {'key': 'hyperparam_xgbclassifier__validate_parameters', 'value': '1'},\n",
       "   {'key': 'hyperparam_xgbclassifier__verbosity', 'value': 'None'},\n",
       "   {'key': 'neomaril_exectuion_id', 'value': '1'}]},\n",
       " 'RunAt': '2023-05-29T13:34:20.4345270Z'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run.execution_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-29 10:37:23.247 | INFO     | neomaril_codex.base:download_result:376 - Output saved in ./output_1.zip\n",
      "2023-05-29 10:37:23.719 | INFO     | neomaril_codex.training:__upload_model:163 - Model 'Teste notebook promoted custom' promoted from Td2d7ca1a7f84110b25bd81f9429a2d026bf16e58d3a4bf59ef55a0fa101c160 - Hash: \"Mba26915630b46c69960b0fd46c13bfc4eeab5196dfd47ea853687585fb69cd0\"\n",
      "2023-05-29 10:37:24.510 | INFO     | neomaril_codex.training:__host_model:225 - Model host in process - Hash: Mba26915630b46c69960b0fd46c13bfc4eeab5196dfd47ea853687585fb69cd0\n",
      "2023-05-29 10:37:24.511 | INFO     | neomaril_codex.model:__init__:66 - Loading .env\n"
     ]
    }
   ],
   "source": [
    "# When the run is finished you can download the model file\n",
    "run.download_result()\n",
    "\n",
    "# or promote promete it to a deployed model\n",
    "\n",
    "PATH = './samples/syncModel/'\n",
    "\n",
    "model = run.promote_model('Teste notebook promoted custom', # model_name\n",
    "                            'score', # name of the scoring function\n",
    "                            PATH+'app.py', # Path of the source file\n",
    "                            PATH+'schema.json', # Path of the schema file, but it could be a dict\n",
    "#                           env=PATH+'.env'  #  File for env variables (this will be encrypted in the server)\n",
    "#                           extra_files=[PATH+'utils.py'], # List with extra files paths that should be uploaded along (they will be all in the same folder)\n",
    "                            operation=\"Sync\" # Can be Sync or Async\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeomarilModel(name=\"Teste notebook promoted custom\", group=\"datarisk\", \n",
       "                                status=\"Building\",\n",
       "                                model_id=\"Mba26915630b46c69960b0fd46c13bfc4eeab5196dfd47ea853687585fb69cd0\",\n",
       "                                operation=\"Sync\",\n",
       "                                schema={\n",
       "  \"mean_radius\": 17.99,\n",
       "  \"mean_texture\": 10.38,\n",
       "  \"mean_perimeter\": 122.8,\n",
       "  \"mean_area\": 1001.0,\n",
       "  \"mean_smoothness\": 0.1184,\n",
       "  \"mean_compactness\": 0.2776,\n",
       "  \"mean_concavity\": 0.3001,\n",
       "  \"mean_concave_points\": 0.1471,\n",
       "  \"mean_symmetry\": 0.2419,\n",
       "  \"mean_fractal_dimension\": 0.07871,\n",
       "  \"radius_error\": 1.095,\n",
       "  \"texture_error\": 0.9053,\n",
       "  \"perimeter_error\": 8.589,\n",
       "  \"area_error\": 153.4,\n",
       "  \"smoothness_error\": 0.006399,\n",
       "  \"compactness_error\": 0.04904,\n",
       "  \"concavity_error\": 0.05373,\n",
       "  \"concave_points_error\": 0.01587,\n",
       "  \"symmetry_error\": 0.03003,\n",
       "  \"fractal_dimension_error\": 0.006193,\n",
       "  \"worst_radius\": 25.38,\n",
       "  \"worst_texture\": 17.33,\n",
       "  \"worst_perimeter\": 184.6,\n",
       "  \"worst_area\": 2019.0,\n",
       "  \"worst_smoothness\": 0.1622,\n",
       "  \"worst_compactness\": 0.6656,\n",
       "  \"worst_concavity\": 0.7119,\n",
       "  \"worst_concave_points\": 0.2654,\n",
       "  \"worst_symmetry\": 0.4601,\n",
       "  \"worst_fractal_dimension\": 0.1189\n",
       "}\n",
       "                                )"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AutoML\n",
    "\n",
    "With AutoML you just need to upload the data and some configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-29 10:37:24.621 | INFO     | neomaril_codex.training:create_training_experiment:719 - New Training 'Teste notebook Training AutoML' inserted.\n",
      "2023-05-29 10:37:24.660 | INFO     | neomaril_codex.training:__upload_training:448 - {\"ExecutionId\":2,\"Message\":\"Training files have been uploaded. Use the execution id '2' to check its status.\"}\n",
      "2023-05-29 10:37:24.845 | INFO     | neomaril_codex.training:__execute_training:472 - Model training starting - Hash: T4c725a84d984525abdc3769ff4026a0b2cebd878135418ca8b9ad217abe9a31\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wating the training run......................."
     ]
    }
   ],
   "source": [
    "# Creating a new training experiment\n",
    "training = client.create_training_experiment('Teste notebook Training AutoML', # Experiment name\n",
    "                                            'Classification', # Model type. Can be Classification, Regression or Unsupervised\n",
    "                                            'AutoML', # Training type. Can be Custom or AutoML\n",
    "                                            group='datarisk' # This is the default group. Create a new one when using for a new project\n",
    "                                            )\n",
    "\n",
    "PATH = './samples/autoML/'\n",
    "\n",
    "run = training.run_training('First test', # Run name\n",
    "                            PATH+'dados.csv', # Path to the file with training data\n",
    "                            conf_dict=PATH+'conf.json', # Path of the configuration file\n",
    "                            wait_complete=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeomarilTrainingExecution(exec_id=\"2\", status=\"Succeeded\")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'trainingExecutionId': '2',\n",
       " 'Status': 'Succeeded',\n",
       " 'Message': '{\\n    \"artifacts\": \"wasbs://mlflow-dev@datariskmlops.blob.core.windows.net/artifacts/2/f04ef381a29a4dbb96d0ff1cb0b61544/artifacts\",\\n    \"mlflow_run_id\": \"f04ef381a29a4dbb96d0ff1cb0b61544\"\\n}'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run.get_status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeomarilTrainingExecution(exec_id=\"2\", status=\"Succeeded\")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-29 10:48:30.126 | INFO     | neomaril_codex.training:__upload_model:163 - Model 'Teste notebook promoted autoML' promoted from T4c725a84d984525abdc3769ff4026a0b2cebd878135418ca8b9ad217abe9a31 - Hash: \"Macbee7fdf434dbd8f6e20bf71a6d41f64cdb629ec7b419e9e4e5c8a4c7e79df\"\n",
      "2023-05-29 10:48:30.149 | INFO     | neomaril_codex.training:__host_model:225 - Model host in process - Hash: Macbee7fdf434dbd8f6e20bf71a6d41f64cdb629ec7b419e9e4e5c8a4c7e79df\n",
      "2023-05-29 10:48:30.152 | INFO     | neomaril_codex.model:__init__:66 - Loading .env\n"
     ]
    }
   ],
   "source": [
    "# Promote a AutoML model is a lot easier\n",
    "\n",
    "PATH = './samples/syncModel/'\n",
    "\n",
    "model = run.promote_model('Teste notebook promoted autoML', # model_name\n",
    "                            operation=\"Async\" # Can be Sync or Async\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeomarilModel(name=\"Teste notebook promoted autoML\", group=\"datarisk\", \n",
       "                                status=\"Building\",\n",
       "                                model_id=\"Macbee7fdf434dbd8f6e20bf71a6d41f64cdb629ec7b419e9e4e5c8a4c7e79df\",\n",
       "                                operation=\"Async\",\n",
       "                                schema={}\n",
       "                                )"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neomaril-codex-WNTK3WJm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "d7308033b61508a213f02f142180c32f76fea0bd8e107ff2b0f7849d3585655c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
